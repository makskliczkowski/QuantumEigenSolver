{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df9afc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"BACKEND\"] = \"numpy\"\n",
    "# Set JAX backend if necessary (often not needed explicitly)\n",
    "# os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\" # or \"gpu\", \"tpu\"\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in locals() else os.getcwd()\n",
    "for i in range(1, 5): # Check up to 4 levels up\n",
    "    dir_up = os.path.abspath(os.path.join(script_dir, *(['..'] * i)))\n",
    "    if dir_up not in sys.path:\n",
    "        sys.path.append(dir_up)\n",
    "    sys.path.append(os.path.join(dir_up, \"QES\", \"general_python\"))\n",
    "\n",
    "# try to import the gymnasium package, this is used to create a custom environment for quantum vector optimization\n",
    "try:\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    import gymnasium as gym\n",
    "    import optax\n",
    "    import flax.linen as nn\n",
    "    from flax.training.train_state import TrainState\n",
    "    from flax.linen.initializers import orthogonal\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing JAX or gymnasium: {e}\")\n",
    "    print(\"Please ensure JAX and gymnasium are installed in your Python environment.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from functools import partial\n",
    "from typing import Optional, Dict, Sequence, NamedTuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# common utilities for logging\n",
    "try:\n",
    "    from QES.general_python.algebra.linalg import _apply_complex_givens_rotation_jax\n",
    "    from QES.general_python.common.flog import Logger, get_global_logger\n",
    "    from QES.general_python.common.directories import Directories\n",
    "    from QES.general_python.common.plot import Plotter\n",
    "    from QES.Algebra.hamil_quadratic import QuadraticSelection\n",
    "    from QES.general_python.physics.entropy_jax import vn_entropy_jax\n",
    "    from QES.general_python.physics.density_matrix_jax import rho_jax, schmidt_jax\n",
    "    from QES.general_python.physics.entropy import EntropyPredictions\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing custom modules (QES, extractors): {e}\")\n",
    "    print(\"Please ensure these modules are in the Python path and are JAX-compatible.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "#! Global Configuration & Initialization\n",
    "\n",
    "# For reproducibility\n",
    "master_seed     = np.random.randint(0, 2**32 - 1) \n",
    "# master_seed = 42 # Or set a fixed seed\n",
    "key             = jax.random.PRNGKey(master_seed)\n",
    "np.random.seed(master_seed)\n",
    "\n",
    "# Logger setup\n",
    "logger          = get_global_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "830056e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_matching_files(files_org_list, gamma_val, ns_val):\n",
    "    '''\n",
    "    Get a random pair of matching ORG and MIX files based on the specified gamma and ns values.\n",
    "    Args:\n",
    "        files_org_list (List[str]):\n",
    "            List of ORG file paths.\n",
    "        gamma_val (int):\n",
    "            The gamma value to filter files.\n",
    "        ns_val (int):\n",
    "            The ns value to filter files.\n",
    "    Returns:\n",
    "        Tuple[str, str]:\n",
    "            A tuple containing the selected ORG file path and the corresponding MIX file path.\n",
    "    Raises:\n",
    "        ValueError: If no matching ORG files are found.\n",
    "    '''\n",
    "    # Filter org files\n",
    "    org_candidates = [str(f) for f in files_org_list if f'gamma={gamma_val}' in str(f) and f'ns={ns_val}' in str(f)]\n",
    "    if not org_candidates:\n",
    "        raise ValueError(f\"No ORG files found with gamma={gamma_val} and ns={ns_val}.\")\n",
    "    \n",
    "    # Randomly select one of the matching org files\n",
    "    selected_org_file = str(np.random.choice(org_candidates))\n",
    "\n",
    "    # Try to find a corresponding mix file. This logic assumes a naming convention. The mix file should have the same name as the org file.\n",
    "    selected_mix_file = selected_org_file.replace('org', 'mix')\n",
    "    logger.info(f\"Selected ORG file: {selected_org_file} (from {len(org_candidates)} matches)\")\n",
    "    logger.info(f\"Selected MIX file: {selected_mix_file} (should match ORG file naming convention)\")\n",
    "    return selected_org_file, selected_mix_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75e0b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_set_of_states(gamma_select, ns, dim_a, dim_b, org_nh):\n",
    "    base_data_dir   = os.path.join(script_dir, 'data')\n",
    "    directory_org   = Directories(os.path.join(base_data_dir, 'org'))\n",
    "    directory_mix   = Directories(os.path.join(base_data_dir, 'mix'))\n",
    "\n",
    "    # List all files in the directories\n",
    "    files_org       = directory_org.list_files(filters=[lambda x: str(x).endswith('.npy')])\n",
    "    files_mix       = directory_mix.list_files(filters=[lambda x: str(x).endswith('.npy')])\n",
    "\n",
    "    # Check if we have any files to process\n",
    "    try:\n",
    "        random_file_org_path, random_file_mix_path = get_random_matching_files(files_org, gamma_select, ns)\n",
    "        \n",
    "        logger.info(f\"Loading original data from: {random_file_org_path}\", lvl = 1, color = 'green')\n",
    "        data_org        = np.load(random_file_org_path)\n",
    "        data_org_jax    = jnp.array(data_org)\n",
    "        logger.info(f\"Loading mixed data from: {random_file_mix_path}\", lvl = 1, color = 'blue')\n",
    "        data_mix        = np.load(random_file_mix_path)\n",
    "        data_mix_jax    = jnp.array(data_mix)\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        logger.error(f\"Error during data loading/selection: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    logger.info(f\"Loaded data_org_jax with shape: {data_org_jax.shape}\", lvl = 1, color = 'green')\n",
    "    logger.info(f\"Loaded data_mix_jax with shape: {data_mix_jax.shape}\", lvl = 1, color = 'green')\n",
    "    logger.info(\"Calculating initial entanglement for a few original states (from data_org_jax):\", lvl = 1, color = 'red')\n",
    "\n",
    "    # Calculate entanglement for the original states\n",
    "    num_states_to_check = min(data_org_jax.shape[1], 5)\n",
    "    gamma               = data_org_jax.shape[1]\n",
    "    entropy_values      = {\n",
    "        'original'      : [],\n",
    "        'mixed'         : [],\n",
    "        'minimum'       : float('inf'),\n",
    "        'maximum'       : float('-inf'),\n",
    "        'minimum_mixed' : float('inf'),\n",
    "        'maximum_mixed' : float('-inf'),\n",
    "        'average'       : 0.0,\n",
    "        'average_mixed' : 0.0,\n",
    "        'submanifold_mp': np.zeros((gamma, ), dtype=int)\n",
    "    }\n",
    "\n",
    "    # Process original states\n",
    "    for i in range(gamma):\n",
    "        state                               = data_org_jax[:, i]\n",
    "        state_norm                          = jnp.linalg.norm(state)\n",
    "        schmidt_values, _                   = schmidt_jax(state, dim_a, dim_b, use_eig=False)\n",
    "        entropy                             = vn_entropy_jax(schmidt_values)\n",
    "        entropy_values['original'].append(entropy)\n",
    "        entropy_values['minimum']           = min(entropy_values['minimum'], entropy)\n",
    "        entropy_values['maximum']           = max(entropy_values['maximum'], entropy)\n",
    "        entropy_values['average']          += entropy / gamma\n",
    "        if i < num_states_to_check:\n",
    "            logger.info(f\"Original state {i}: Entropy = {entropy:.5f}\", color='blue', lvl=2)\n",
    "\n",
    "    # Set the submanifold_mp values based on the unique entropies of the original states\n",
    "    unique_entropies                        = np.unique(entropy_values['original'])\n",
    "    for i, entropy in enumerate(entropy_values['original']):\n",
    "        entropy_values['submanifold_mp'][i] = np.where(unique_entropies == entropy)[0][0]\n",
    "    logger.info(f\"Submanifold MP values: {entropy_values['submanifold_mp']}\", color='purple', lvl=2)\n",
    "    \n",
    "    # Process mixed states\n",
    "    for i in range(gamma):\n",
    "        state                               = data_mix_jax[:, i]\n",
    "        state_norm                          = jnp.linalg.norm(state)\n",
    "        schmidt_values, _                   = schmidt_jax(state, dim_a, dim_b, use_eig=False)\n",
    "        entropy                             = vn_entropy_jax(schmidt_values)\n",
    "        entropy_values['mixed'].append(entropy)\n",
    "        entropy_values['minimum_mixed']     = min(entropy_values['minimum_mixed'], entropy)\n",
    "        entropy_values['maximum_mixed']     = max(entropy_values['maximum_mixed'], entropy)\n",
    "        entropy_values['average_mixed']    += entropy / gamma\n",
    "        if i < num_states_to_check:\n",
    "            logger.info(f\"Mixed state {i}: Entropy = {entropy:.5f}\", color='purple', lvl=2)\n",
    "\n",
    "    # Log summary statistics\n",
    "    logger.info(f\"Original states entropy summary:\", lvl=1, color='green')\n",
    "    logger.info(f\"      Minimum: {entropy_values['minimum']:.5f}\", color='blue', lvl=1)\n",
    "    logger.info(f\"      Maximum: {entropy_values['maximum']:.5f}\", color='red', lvl=1)\n",
    "    logger.info(f\"      Average: {entropy_values['average']:.5f}\", color='green', lvl=1)\n",
    "\n",
    "    logger.info(f\"Mixed states entropy summary:\", lvl=1, color='yellow')\n",
    "    logger.info(f\"      Minimum: {entropy_values['minimum_mixed']:.5f}\", color='blue', lvl=1)\n",
    "    logger.info(f\"      Maximum: {entropy_values['maximum_mixed']:.5f}\", color='red', lvl=1)\n",
    "    logger.info(f\"      Average: {entropy_values['average_mixed']:.5f}\", color='green', lvl=1)\n",
    "\n",
    "    # Calculate entropy difference\n",
    "    avg_entropy_diff = entropy_values['average_mixed'] - entropy_values['average']\n",
    "    logger.info(f\"Average entropy increase after mixing: {avg_entropy_diff:.5f}\", color='yellow', lvl=2)\n",
    "\n",
    "    # Return the loaded data and entropy values\n",
    "    return data_org_jax, data_mix_jax, entropy_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38455dd7",
   "metadata": {},
   "source": [
    "## Learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a7df7",
   "metadata": {},
   "source": [
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71acd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEntanglementEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A gymnasium.Env for minimizing entanglement entropy.\n",
    "\n",
    "    - Observation   : Flattened complex unitary matrix V (real and imag parts concatenated).\n",
    "    - Action        : A discrete integer mapping to a specific Givens rotation (i, j, angle_idx).\n",
    "    - Reward        : The reduction in total entanglement entropy from the previous step.\n",
    "    \"\"\"\n",
    "    metadata = {'render_modes': ['human'], 'render_fps': 4}\n",
    "    \n",
    "    def __init__(self, \n",
    "                Gamma               : int,                                              # Number of coefficients (Gamma) - how many states do we mix\n",
    "                la                  : int,                                              # Number of qubits in subsystem A (log2 of dim_a) - in the original basis\n",
    "                org_states          : jnp.ndarray,                                      # Original states in the environment (shape: [dim_a * dim_b, Gamma]) - only Gamma matters for us        \n",
    "                org_states_info     : Optional[Dict]                        = None,     # Additional information about the original states (not used in this implementation)\n",
    "                modify_org_states   : bool                                  = True,      # Whether to modify the original states\n",
    "                K                   : int                                   = 10,       # Discrete action space size\n",
    "                max_steps           : int                                   = 1000,     # Maximum number of steps in the environment\n",
    "                reg_lambda_norm     : float                                 = 0.1):     # Regularization parameter for norm penalty\n",
    "        \n",
    "        # Initialize the environment with the given parameters.\n",
    "        super().__init__()\n",
    "        \n",
    "        # Validate the input parameters\n",
    "        if not isinstance(Gamma, int) or Gamma <= 0:\n",
    "            raise ValueError(\"Gamma must be a positive integer.\")\n",
    "        if not isinstance(la, int) or la <= 0:\n",
    "            raise ValueError(\"dim_a must be a positive integer.\")\n",
    "        if not isinstance(org_states, jnp.ndarray) or org_states.ndim != 2:\n",
    "            raise ValueError(\"org_states must be a 2D JAX array (shape: [dim_a * dim_b, Gamma]).\")\n",
    "        if not isinstance(K, int) or K <= 0:\n",
    "            raise ValueError(\"K must be a positive integer.\")\n",
    "        \n",
    "        #!TODO: Modify this so we can use masks rather than subsystem A and B on the left and right\n",
    "        self.full_nh                    = org_states.shape[0]               # Full Hilbert space dimension\n",
    "        self.ns                         = int(np.log2(self.full_nh))        # Number of qubits (log2 of full Hilbert space dimension)\n",
    "        self.dim_a                      = 2**(la)                           # Dimension of subsystem A (2^la)  \n",
    "        self.dim_b                      = 2**(self.ns - la)                 # Dimension of the subsystems A and B\n",
    "        self.gamma_dim                  = Gamma                             # Number of coefficients (Gamma)\n",
    "        self.max_steps                  = max_steps                         # Maximum number of steps in the environment\n",
    "        self.reg_lambda_norm            = reg_lambda_norm                   # Regularization parameter for norm penalty\n",
    "        self.org_states                 = jnp.asarray(org_states)           # Original states in the environment\n",
    "        self.org_states_modify          = modify_org_states                 # Whether to modify the original states\n",
    "        self.org_states_learn           = jnp.copy(self.org_states) if modify_org_states else self.org_states # Copy of original states for learning\n",
    "        self.org_states_info            = org_states_info if org_states_info is not None else {} # Additional information about the original states\n",
    "        self.page_value                 = EntropyPredictions.Mean.page(da=self.dim_a, db=self.dim_b)\n",
    "\n",
    "        # Define the discrete action space\n",
    "        self._delta_theta               = jnp.pi / (2 * K) if K > 0 else 0\n",
    "        # phase_angles                    = [0.0, jnp.pi/2, jnp.pi, 3*jnp.pi/2] # discrete phases - should I add more?\n",
    "        phase_angles                    = [0.0]\n",
    "\n",
    "        self.action_map                 = []\n",
    "        for i, j in itertools.combinations(range(self.Gamma), 2):\n",
    "            for angle_idx in range(-K, K + 1):\n",
    "                theta = angle_idx * self._delta_theta\n",
    "                for phi in phase_angles:\n",
    "                    self.action_map.append({'i': i, 'j': j, 'theta': theta, 'phi': phi})\n",
    "        \n",
    "        # Define Gym spaces\n",
    "        self.action_space               = gym.spaces.Discrete(len(self.action_map))\n",
    "        obs_shape                       = (2 * Gamma * Gamma,)              # Flattened observation shape: real and imaginary parts of coefficients\n",
    "        self.observation_space          = gym.spaces.Box(low=-1.0, high=1.0, shape=obs_shape, dtype=np.float32)\n",
    "\n",
    "        # Environment state variables\n",
    "        self.V                          = None                              # Unitary matrix V\n",
    "        self.R                          = None                              # Stores the combined rotation matrix\n",
    "        self.current_total_entropy      = None                              # Current total entanglement entropy         \n",
    "        self.current_total_entropy_min  = None                              # Minimum total entanglement entropy observed\n",
    "        self.current_total_entropy_max  = None                              # Maximum total entanglement entropy observed\n",
    "        self.transformed_states         = None                              # Transformed states after applying the unitary V\n",
    "        self.step_count                 = 0                                 # Step counter - tracks the number of steps taken in the environment\n",
    "    \n",
    "    #############################################\n",
    "    #! Properties\n",
    "    #############################################\n",
    "    \n",
    "    @property\n",
    "    def Gamma(self) -> int:\n",
    "        '''\n",
    "        Returns the number of coefficients (Gamma) in the environment.\n",
    "        Returns:\n",
    "            int: The number of coefficients (Gamma).\n",
    "        '''\n",
    "        return self.gamma_dim\n",
    "\n",
    "    #############################################\n",
    "    #! Calculators\n",
    "    #############################################\n",
    "    \n",
    "    def _calculate_total_entropy(self, V: jnp.ndarray) -> jnp.ndarray:\n",
    "        '''\n",
    "        Calculate the total entanglement entropy for the transformed states after applying the unitary V.\n",
    "        Parameters:\n",
    "            V (jnp.ndarray):\n",
    "                The unitary matrix V to apply to the original states.\n",
    "        Returns:\n",
    "            total_entropy (jnp.ndarray):\n",
    "                The total entanglement entropy of the transformed states.\n",
    "        '''\n",
    "        \n",
    "        # 1. Create the final states by mixing the basis states: ψ̃ = Φ @ V\n",
    "        # Shape: (N, Γ) @ (Γ, Γ) -> (N, Γ)\n",
    "        self.transformed_states         = self.org_states_learn @ V\n",
    "        \n",
    "        # 2. Calculate entropy for each of the Γ columns (states)\n",
    "        entropies = jax.vmap(lambda state: vn_entropy_jax(schmidt_jax(state, self.dim_a, self.dim_b, use_eig=False)[0]), in_axes=1)(self.transformed_states)\n",
    "        \n",
    "        # 3. Return the sum of entropies\n",
    "        return jnp.sum(entropies), jnp.min(entropies), jnp.max(entropies), entropies\n",
    "\n",
    "    def _reset_states_info(self):\n",
    "        '''\n",
    "        Resets the original states information to an empty state.\n",
    "        This method is used to clear the original states information when resetting the environment.\n",
    "        '''\n",
    "        self.org_states_info = {\n",
    "            'original'          : [],\n",
    "            'minimum'           : float('inf'),\n",
    "            'maximum'           : float('-inf'),\n",
    "            'average'           : 0.0,\n",
    "            'mixed'             : [],\n",
    "            'minimum_mixed'     : float('inf'),\n",
    "            'maximum_mixed'     : float('-inf'),\n",
    "            'average_mixed'     : 0.0,\n",
    "            'submanifold_mp'    : np.zeros((self.Gamma,), dtype=int)  # Submanifold mapping for entropy values\n",
    "        }\n",
    "        for g in range(self.Gamma):\n",
    "            state               = self.org_states[:, g]\n",
    "            schmidt_values, _   = schmidt_jax(state, self.dim_a, self.dim_b, use_eig=False)\n",
    "            entropy             = vn_entropy_jax(schmidt_values)\n",
    "            \n",
    "            #! fill up the mixed states info if it is empty\n",
    "            self.org_states_info['mixed'].append(entropy)\n",
    "            self.org_states_info['minimum_mixed']   = min(self.org_states_info['minimum_mixed'], entropy)\n",
    "            self.org_states_info['maximum_mixed']   = max(self.org_states_info['maximum_mixed'], entropy)\n",
    "            self.org_states_info['average_mixed']  += entropy / self.Gamma\n",
    "            \n",
    "            #! fill out the original states info if it is empty\n",
    "            self.org_states_info['original'].append(entropy)\n",
    "            self.org_states_info['minimum']         = min(self.org_states_info['minimum'], entropy)\n",
    "            self.org_states_info['maximum']         = max(self.org_states_info['maximum'], entropy)\n",
    "            self.org_states_info['average']        += entropy / self.Gamma\n",
    "    \n",
    "    #############################################\n",
    "    #! Environment API Methods\n",
    "    #############################################\n",
    "\n",
    "    def reset(self, seed: int = None, options: Dict = None):\n",
    "        '''\n",
    "        Resets the environment to an initial state.\n",
    "        Parameters:\n",
    "            seed (int, optional):\n",
    "                Random seed for reproducibility. If None, a random seed will be generated.\n",
    "            options (Dict, optional):\n",
    "                Additional options for resetting the environment (not used in this implementation).\n",
    "        Returns:\n",
    "            obs (np.ndarray):\n",
    "                The initial observation of the environment, which is a flattened array of the real and imaginary parts of the coefficients.\n",
    "            info (Dict):\n",
    "                Additional information about the reset state, such as the initial loss value.\n",
    "        Raises:\n",
    "            ValueError:\n",
    "                If the initial coefficients do not match the expected shape or norm.\n",
    "        '''\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        \n",
    "        # The agent's state V is a ΓxΓ identity matrix\n",
    "        self.step_count                 = 0\n",
    "        self.V                          = jnp.eye(self.Gamma, dtype=jnp.complex64)\n",
    "        self.R                          = jnp.eye(self.Gamma, dtype=jnp.complex64)\n",
    "\n",
    "        if len(self.org_states_info) == 0:\n",
    "            self._reset_states_info()  # Reset the original states info if it is empty\n",
    "        \n",
    "        if self.org_states_modify:\n",
    "            U_org                           = jnp.array(QuadraticSelection.haar_random_unitary(self.Gamma, dtype=jnp.complex64))\n",
    "            # If we modify the original states, we need to create a copy of them\n",
    "            self.org_states_learn           = self.org_states @ U_org\n",
    "            entro                           = self._calculate_total_entropy(U_org)\n",
    "            self.current_total_entropy      = entro[0]\n",
    "            self.current_total_entropy_min  = entro[1]\n",
    "            self.current_total_entropy_max  = entro[2]\n",
    "            self.current_entropies          = entro[3]\n",
    "        else:\n",
    "            self.current_total_entropy      = self.org_states_info['average_mixed'] * self.Gamma\n",
    "            self.current_total_entropy_min  = self.org_states_info['minimum_mixed']\n",
    "            self.current_total_entropy_max  = self.org_states_info['maximum_mixed']\n",
    "            self.current_entropies          = jnp.array(self.org_states_info['mixed'], dtype=jnp.float32)\n",
    "        \n",
    "        # set the transformed states again\n",
    "        obs                         = jnp.concatenate([self.V.real.flatten(), self.V.imag.flatten()])\n",
    "        info                        = { 'total_entropy' : self.current_total_entropy,\n",
    "                                        'min_entropy'   : self.current_total_entropy_min, \n",
    "                                        'max_entropy'   : self.current_total_entropy_max }\n",
    "        return np.array(obs), info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        \"\"\"Performs one step in the environment.\"\"\"\n",
    "        \n",
    "        # Update the step count\n",
    "        self.step_count    += 1\n",
    "        \n",
    "        # Action parameters are for a rotation in Γ-space\n",
    "        action_params       = self.action_map[action]\n",
    "        i, j, theta, phi    = action_params['i'], action_params['j'], action_params['theta'], action_params.get('phi', 0.0)\n",
    "\n",
    "        # Build the new ΓxΓ unitary\n",
    "        new_V               = _apply_complex_givens_rotation_jax(self.V, i, j, theta, phi, self.Gamma)\n",
    "\n",
    "        # Calculate new entropy using the black-box function\n",
    "        entropy_values          = self._calculate_total_entropy(new_V)\n",
    "        new_total_entropy       = entropy_values[0]\n",
    "        individual_entropies    = entropy_values[3]\n",
    "        \n",
    "        entropy_reduction       = self.current_total_entropy - new_total_entropy\n",
    "        normalized_reward       = entropy_reduction / self.page_value\n",
    "        if normalized_reward < 0:\n",
    "            reward_entropy      = normalized_reward * 1.5 # Penalize bad steps more\n",
    "        else:\n",
    "            reward_entropy = normalized_reward\n",
    "        \n",
    "        #! Regularization to penalize variance in the transformed states\n",
    "        variance_penalty    = 0\n",
    "        if self.org_states_info['submanifold_mp'] is not None:\n",
    "            num_submanifolds = len(self.org_states_info['submanifold_mp'])\n",
    "            for i in range(num_submanifolds):\n",
    "                entropies_in_submanifold = individual_entropies[self.org_states_info['submanifold_mp'] == i]\n",
    "                if len(entropies_in_submanifold) > 0:\n",
    "                    variance_penalty += jnp.var(entropies_in_submanifold)\n",
    "        variance_penalty   /= num_submanifolds if num_submanifolds > 0 else 1\n",
    "        lambda_variance     = 0.2\n",
    "        # reward_entropy     -= lambda_variance * variance_penalty        # Regularization term to penalize variance in entropies\n",
    "        \n",
    "        # Overlaps with the original states\n",
    "        # overlaps            = jax.vmap(jnp.vdot, in_axes=(1, 1))(self.org_states, self.transformed_states)\n",
    "        # overlap_penalty     = jnp.mean(jnp.abs(overlaps)**2)\n",
    "        # reward_entropy     -= self.reg_lambda_norm * overlap_penalty    # Regularization term to penalize overlaps\n",
    "        overlap_penalty     = 0.0 # Overlap penalty is not used in this implementation, but can be added if needed\n",
    "\n",
    "        # Update the environment state\n",
    "        self.V                          = new_V\n",
    "        self.R                          = self.R @ new_V                # Update the combined rotation matrix\n",
    "        self.current_total_entropy      = new_total_entropy             # Update the current total entropy\n",
    "        self.current_total_entropy_min  = entropy_values[1]             # Update the current minimum total entropy\n",
    "        self.current_total_entropy_max  = entropy_values[2]             # Update the current maximum total entropy\n",
    "        self.current_entropies          = entropy_values[3]             # Update the current entropies for each state\n",
    "    \n",
    "        terminated          = False\n",
    "        truncated           = self.step_count >= self.max_steps\n",
    "\n",
    "        obs                 = jnp.concatenate([self.V.real.flatten(), self.V.imag.flatten()])\n",
    "        info                = { 'total_entropy'     : self.current_total_entropy, \n",
    "                                'min_entropy'       : self.current_total_entropy_min,\n",
    "                                'max_entropy'       : self.current_total_entropy_max, \n",
    "                                'variance_penalty'  : variance_penalty,\n",
    "                                'overlap_penalty'   : overlap_penalty }\n",
    "\n",
    "        return np.array(obs), float(reward_entropy), terminated, truncated, info\n",
    "\n",
    "    def step_sparse(self, action: int):\n",
    "        self.step_count    += 1\n",
    "        params              = self.action_map[action]\n",
    "        \n",
    "        # 1. Always update the unitary. This is a cheap operation.\n",
    "        self.V              = _apply_complex_givens_rotation_jax(self.V, params['i'], params['j'], params['theta'], self.Gamma)\n",
    "\n",
    "        # 2. Check if the episode is ending on THIS step\n",
    "        truncated           = self.step_count >= self.max_steps\n",
    "        terminated          = False     # No natural termination condition\n",
    "        if truncated:\n",
    "            return self.step(action)    # If we are at the end, just call the regular step function\n",
    "        # --- SPARSE REWARD LOGIC ---\n",
    "        # This is an intermediate step. Reward is zero.\n",
    "        # No expensive calculations are performed.\n",
    "        reward  = 0.0\n",
    "        \n",
    "        # The info dict can just report the last known entropy from reset or be empty\n",
    "        info    = {'total_entropy': self.current_total_entropy.item(), 'overlap_penalty': 0.0}\n",
    "\n",
    "        # 3. Return standard gym signature\n",
    "        obs     = jnp.concatenate([self.V.real.flatten(), self.V.imag.flatten()])\n",
    "        return np.array(obs), float(reward), terminated, truncated, info\n",
    "\n",
    "    def render(self, mode: str = 'human'):\n",
    "        \"\"\"\n",
    "        Render the environment's current state using the notebook logger.\n",
    "        Reports:\n",
    "            - step count\n",
    "            - unitary-norm check (Frobenius norm / Γ)\n",
    "            - total entanglement entropy\n",
    "            - per-state entropy statistics (min / avg / max)\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode != 'human':\n",
    "            return\n",
    "\n",
    "        # Norm check: ⟨V, V⟩ / Γ\n",
    "        norm_sq     = jnp.trace(self.V @ self.V.T.conj()).real / self.Gamma\n",
    "\n",
    "        # Log via notebook logger\n",
    "        text        =   f\"Step {self.step_count} | Norm(Fro/Γ): {norm_sq:.6f} | TotalEntropy: {self.current_total_entropy:.6f} \" \\\n",
    "                        f\"| per-state [min: {self.current_total_entropy_min:.6f}, max: {self.current_total_entropy_max:.6f}]\"\n",
    "        logger.info(text, lvl = 1, color = 'blue')\n",
    "\n",
    "    ##############################################\n",
    "    #! Sanity Check\n",
    "    ##############################################\n",
    "    \n",
    "    def sanity(self):\n",
    "        logger.title(\"Sanity Check: Greedy One-Step Search\", desired_size=80, fill='-', color='cyan', lvl=1)\n",
    "        \n",
    "        #! Reset the environment to get the initial state and entropy info\n",
    "        obs, info           = self.reset()  # Reset the environment to get the initial state and entropy info\n",
    "        initial_entropy     = info['total_entropy']\n",
    "        logger.info(f\"Initial Total Entropy: {initial_entropy:.5f}\", color='blue', lvl=2)\n",
    "\n",
    "        best_reward         = -float('inf')\n",
    "        best_action         = -1\n",
    "\n",
    "        for action in range(self.action_space.n):\n",
    "            # We need to simulate a step without actually changing the env state for the next loop\n",
    "            action_params       = self.action_map[action]\n",
    "            i, j, theta, phi    = action_params['i'], action_params['j'], action_params['theta'], action_params.get('phi', 0.0)\n",
    "            \n",
    "            # Apply the rotation to a copy of the current V matrix\n",
    "            new_V               = _apply_complex_givens_rotation_jax(self.V, i, j, theta, phi, self.Gamma)\n",
    "\n",
    "            # Calculate the resulting entropy and reward\n",
    "            new_entropy         = self._calculate_total_entropy(new_V)[0]\n",
    "            reward              = initial_entropy - new_entropy\n",
    "            logger.info(f\"Action {action}: Entropy after action = {new_entropy:.5f}, Reward = {reward:.5f}\", color='green', lvl = 3)\n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                best_action = action\n",
    "\n",
    "        logger.info(f\"Best possible one-step reward: {best_reward:.5f}\", color='green', lvl=2)\n",
    "        logger.info(f\"Achieved with action: {best_action}\", color='green', lvl=2)\n",
    "\n",
    "        if best_reward > 0:\n",
    "            logger.info(\"SUCCESS: There are actions that immediately reduce entropy.\", color='green', lvl=1)\n",
    "        else:\n",
    "            logger.warning(\"WARNING: No single action from the start reduces entropy. The problem might be too hard or the reward is ill-defined.\", color='red', lvl=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cd301",
   "metadata": {},
   "source": [
    "#### Action Critic using PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7f1bbcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    \"\"\"\n",
    "    State-of-the-art Actor-Critic for PPO adapted to quantum control tasks.\n",
    "\n",
    "    Policy: Gaussian distribution \\(\\pi_\\theta(a|s)=\\mathcal{N}(a; \\mu_\\theta(s), \\mathrm{diag}(\\sigma^2))\\)\n",
    "    Value: \\(V_\\phi(s)\\)\n",
    "    \"\"\"\n",
    "    action_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.ndarray):\n",
    "        \n",
    "        x = nn.Dense(128)(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = nn.tanh(x)\n",
    "\n",
    "        x = nn.Dense(128)(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = nn.tanh(x)\n",
    "        \n",
    "        x = nn.Dense(128)(x)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = nn.tanh(x)\n",
    "            \n",
    "        # --- Actor Head ---\n",
    "        logits = nn.Dense(self.action_dim, kernel_init=nn.initializers.orthogonal(0.01), name=\"actor_logits\")(x)\n",
    "\n",
    "        # --- Critic Head ---\n",
    "        v = nn.Dense(128)(x)\n",
    "        v = nn.LayerNorm()(v)\n",
    "        v = nn.tanh(v)\n",
    "\n",
    "        v = nn.Dense(128)(v)\n",
    "        v = nn.LayerNorm()(v)\n",
    "        v = nn.tanh(v)\n",
    "        \n",
    "        v = nn.Dense(1, kernel_init=nn.initializers.orthogonal(1.0), name=\"critic_value\")(v)\n",
    "        \n",
    "        return logits, jnp.squeeze(v, -1)\n",
    "\n",
    "class Transition(NamedTuple):\n",
    "    done        : jnp.ndarray\n",
    "    action      : jnp.ndarray\n",
    "    value       : jnp.ndarray\n",
    "    reward      : jnp.ndarray\n",
    "    log_prob    : jnp.ndarray\n",
    "    obs         : jnp.ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8719f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent:\n",
    "    '''\n",
    "    Proximal Policy Optimization (PPO) Agent for Quantum Entanglement Minimization.\n",
    "    This agent uses an Actor-Critic architecture to learn a policy that minimizes entanglement entropy in a quantum system.\n",
    "    Attributes:\n",
    "        obs_shape (Sequence[int]):\n",
    "            The shape of the observation space, which is used to initialize the actor-critic network.\n",
    "        action_dim (int):\n",
    "            The dimension of the action space, which determines the output size of the actor's head in the network.\n",
    "        config (Dict):\n",
    "            Configuration dictionary containing hyperparameters for the agent, such as learning rate, optimizer, and GAE parameters.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, obs_shape: Sequence[int], action_dim: int, config: Dict):\n",
    "        self.config         = config\n",
    "        self.obs_shape      = obs_shape\n",
    "        self.action_dim     = action_dim\n",
    "        self.key            = jax.random.PRNGKey(config[\"SEED\"])\n",
    "        \n",
    "        # Config info\n",
    "        self.lr             = config.get(\"LEARNING_RATE\", 3e-4)                             # Learning rate for the optimizer\n",
    "        self.optimizer      = config.get(\"OPTIMIZER\", optax.adam(learning_rate=self.lr))\n",
    "        self.maxgrad_norm   = config.get(\"MAX_GRAD_NORM\", 0.5)\n",
    "        \n",
    "        # Initialize the actor-critic network\n",
    "        self.network        = ActorCritic(action_dim=self.action_dim)\n",
    "        self._init_agent()\n",
    "    \n",
    "    def _init_agent(self):\n",
    "        \"\"\"Initializes the network parameters and the optimizer train state.\"\"\"\n",
    "        self.key, network_key   = jax.random.split(self.key)        # Split the key for network initialization\n",
    "        init_obs                = jnp.zeros((1, *self.obs_shape))   # Initial observation for network initialization\n",
    "        network_params          = self.network.init(network_key, init_obs)[\"params\"]\n",
    "\n",
    "        tx                      = optax.chain(optax.clip_by_global_norm(self.maxgrad_norm), self.optimizer)\n",
    "        self.train_state        = TrainState.create(apply_fn=self.network.apply, params=network_params, tx=tx)\n",
    "\n",
    "    #############################\n",
    "    #! Agent API Methods\n",
    "    #############################\n",
    "    \n",
    "    def _get_action_and_value(self, obs: np.ndarray, key: jax.random.key) -> (jnp.ndarray, jnp.ndarray, jnp.ndarray):\n",
    "        \"\"\"Uses the network to get an action and its value for a given observation.\"\"\"\n",
    "        logits, v   = self.network.apply({\"params\": self.train_state.params}, obs[None, :])\n",
    "        logits, v   = logits[0], v[0]\n",
    "\n",
    "        key, subkey = jax.random.split(key)\n",
    "        # categorical sample\n",
    "        action      = jax.random.categorical(subkey, logits)\n",
    "        logp        = jax.nn.log_softmax(logits)[action]\n",
    "        return int(action), float(logp), float(v), key\n",
    "\n",
    "    def get_action(self, obs: np.ndarray):\n",
    "        \"\"\"Gets an action from the agent for a single observation.\"\"\"\n",
    "        self.key, subkey = jax.random.split(self.key)\n",
    "        return self._get_action_and_value(jnp.array(obs), subkey)[:3]\n",
    "\n",
    "    def learn(self, transitions: Transition, last_obs: Optional[np.ndarray] = None):\n",
    "        \"\"\"Updates the agent's parameters using a batch of transitions.\"\"\"\n",
    "        \n",
    "        if last_obs is None:\n",
    "            last_obs = transitions.obs[-1]\n",
    "            \n",
    "        # 1) calculate GAE\n",
    "        _, _, last_val, _   = self._get_action_and_value(jnp.array(last_obs), self.key)\n",
    "        advantages, returns = self._calculate_gae(transitions, last_val, self.config[\"GAMMA_DISCOUNT\"], self.config[\"GAE_LAMBDA\"])\n",
    "\n",
    "        # 2) Define the update function for an entire epoch\n",
    "        @jax.jit\n",
    "        def _update_epoch(carry, _):\n",
    "            train_state, key    = carry\n",
    "            \n",
    "            # Create a new permutation for shuffling data this epoch\n",
    "            key, perm_key       = jax.random.split(key)\n",
    "            B, M                = self.config[\"NUM_STEPS\"], self.config[\"MINIBATCH_SIZE\"]\n",
    "            permutation         = jax.random.permutation(perm_key, B)\n",
    "            \n",
    "            # Reshape data for minibatching and shuffle\n",
    "            batch_data = (\n",
    "                transitions.obs[permutation], \n",
    "                transitions.action[permutation],\n",
    "                transitions.log_prob[permutation],\n",
    "                transitions.value[permutation],\n",
    "                advantages[permutation],\n",
    "                returns[permutation]\n",
    "            )\n",
    "            batch_data = jax.tree.map(\n",
    "                lambda x: x.reshape((B // M, M) + x.shape[1:]), batch_data\n",
    "            )\n",
    "\n",
    "            # 3) loss + jit update\n",
    "            def loss_fn(params, minibatch):\n",
    "                obs_mb, act_mb, old_lp_mb, old_v_mb, adv_mb, ret_mb = minibatch\n",
    "                logits, v_new                                       = self.network.apply({\"params\": params}, obs_mb)\n",
    "                \n",
    "                # Policy Loss (with Advantage Normalization)\n",
    "                adv_norm                = (adv_mb - jnp.mean(adv_mb)) / (jnp.std(adv_mb) + 1e-8)\n",
    "                \n",
    "                logp_all                = jax.nn.log_softmax(logits)\n",
    "                logp_new                = jnp.take_along_axis(logp_all, act_mb[..., None], axis=1)[:, 0]\n",
    "                ratio                   = jnp.exp(logp_new - old_lp_mb)\n",
    "                \n",
    "                clipped_ratio           = jnp.clip(ratio, 1 - self.config[\"CLIP_EPS\"], 1 + self.config[\"CLIP_EPS\"])\n",
    "                policy_obj              = jnp.minimum(ratio * adv_norm, clipped_ratio * adv_norm).mean()\n",
    "\n",
    "                # --- Value Loss ---\n",
    "                # Optional: Add value clipping for more stability\n",
    "                v_pred_clipped          = old_v_mb + (v_new - old_v_mb).clip(-self.config[\"CLIP_EPS\"], self.config[\"CLIP_EPS\"])\n",
    "                v_loss_unclipped        = (v_new - ret_mb)**2\n",
    "                v_loss_clipped          = (v_pred_clipped - ret_mb)**2\n",
    "                v_err                   = 0.5 * jnp.maximum(v_loss_unclipped, v_loss_clipped).mean()\n",
    "                # v_err = jnp.mean((v_new - ret_mb)**2)\n",
    "\n",
    "                # Entropy Bonus\n",
    "                entropy                 = -jnp.mean(jnp.sum(jnp.exp(logp_all) * logp_all, axis=1))\n",
    "\n",
    "                # Total Objective & Loss\n",
    "                J                       = policy_obj - self.config[\"VF_COEF\"] * v_err + self.config.get(\"ENT_COEF\", 0.01) * entropy\n",
    "                loss                    = -J\n",
    "\n",
    "                metrics                 = {\n",
    "                                            \"total_loss\"    : loss,\n",
    "                                            \"policy_obj\"    : policy_obj,\n",
    "                                            \"value_loss\"    : v_err,\n",
    "                                            \"entropy\"       : entropy\n",
    "                                        }\n",
    "                return loss, metrics\n",
    "\n",
    "            # Define the update step for a single minibatch\n",
    "            def _update_minibatch(state, minibatch):\n",
    "                (loss, metrics), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params, minibatch)\n",
    "                new_state = state.apply_gradients(grads=grads)\n",
    "                return new_state, metrics\n",
    "\n",
    "            # Scan over all minibatches to update and collect metrics\n",
    "            final_state, metrics = jax.lax.scan(_update_minibatch, train_state, batch_data)\n",
    "            \n",
    "            # Return the updated state and the mean metrics for this epoch\n",
    "            return (final_state, key), jax.tree.map(jnp.mean, metrics)\n",
    "\n",
    "        # 3) Run update over all epochs\n",
    "        # Use lax.scan for the epoch loop as well, for JIT-compatibility\n",
    "        (final_train_state, self.key), metrics  = jax.lax.scan(_update_epoch, (self.train_state, self.key), None, self.config[\"UPDATE_EPOCHS\"])\n",
    "        self.train_state                        = final_train_state\n",
    "        \n",
    "        # Return the mean metrics over the final epoch\n",
    "        return jax.tree.map(lambda x: x.mean(), metrics)\n",
    "\n",
    "\n",
    "    ############################\n",
    "    #! Private Methods\n",
    "    ############################\n",
    "\n",
    "    @staticmethod\n",
    "    @jax.jit\n",
    "    def _calculate_gae(transitions: Transition, last_val: jnp.ndarray, gamma: float = 0.99, gae_lambda: float = 0.95):\n",
    "        \"\"\"Computes Generalized Advantage Estimation in a JAX-friendly way using scan.\"\"\"\n",
    "        \n",
    "        # We need to reverse the transitions for the scan\n",
    "        transitions_rev = jax.tree.map(lambda x: x[::-1], transitions)\n",
    "        \n",
    "        def _gae_step(carry, transition_slice):\n",
    "            gae, next_val       = carry\n",
    "            # A slice of the Transition tuple for one time-step\n",
    "            done, value, reward = transition_slice.done, transition_slice.value, transition_slice.reward\n",
    "            \n",
    "            next_non_terminal   = 1.0 - done\n",
    "            delta               = reward + gamma * next_val * next_non_terminal - value\n",
    "            gae                 = delta + gamma * gae_lambda * next_non_terminal * gae\n",
    "            \n",
    "            # The new `next_val` for the next iteration is the `value` of the current state\n",
    "            return (gae, value), gae\n",
    "\n",
    "        # The initial carry for the scan is (0, last_val)\n",
    "        # gae starts at 0, and the first next_val is the value of the final state (last_val)\n",
    "        _, advantages_rev = jax.lax.scan(_gae_step, (0.0, last_val), transitions_rev)\n",
    "\n",
    "        # Reverse the advantages to get them in the correct order\n",
    "        advantages = advantages_rev[::-1]\n",
    "        return advantages, advantages + transitions.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe26561",
   "metadata": {},
   "source": [
    "#### Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a25406f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_06_2025_13-10_00 [INFO] Selected ORG file: /home/klimak/Codes/QuantumEigenSolver/Python/projects/2025/degenerate_entanglement/reinforced/data/org/ff,E=0.58579,ns=8,gamma=4.npy (from 2 matches)\n",
      "09_06_2025_13-10_00 [INFO] Selected MIX file: /home/klimak/Codes/QuantumEigenSolver/Python/projects/2025/degenerate_entanglement/reinforced/data/mix/ff,E=0.58579,ns=8,gamma=4.npy (should match ORG file naming convention)\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32mLoading original data from: /home/klimak/Codes/QuantumEigenSolver/Python/projects/2025/degenerate_entanglement/reinforced/data/org/ff,E=0.58579,ns=8,gamma=4.npy\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[34mLoading mixed data from: /home/klimak/Codes/QuantumEigenSolver/Python/projects/2025/degenerate_entanglement/reinforced/data/mix/ff,E=0.58579,ns=8,gamma=4.npy\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32mLoaded data_org_jax with shape: (256, 4)\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32mLoaded data_mix_jax with shape: (256, 4)\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[31mCalculating initial entanglement for a few original states (from data_org_jax):\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[34mOriginal state 0: Entropy = 1.52614\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[34mOriginal state 1: Entropy = 1.92919\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[34mOriginal state 2: Entropy = 1.92919\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[34mOriginal state 3: Entropy = 1.52614\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[0mSubmanifold MP values: [0 2 1 0]\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[0mMixed state 0: Entropy = 2.03626\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[0mMixed state 1: Entropy = 1.78759\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[0mMixed state 2: Entropy = 1.83523\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[0mMixed state 3: Entropy = 1.93126\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32mOriginal states entropy summary:\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[34m      Minimum: 1.52614\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[31m      Maximum: 1.92919\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32m      Average: 1.72767\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[33mMixed states entropy summary:\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[34m      Minimum: 1.78759\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[31m      Maximum: 2.03626\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32m      Average: 1.89758\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t\t->\u001b[33mAverage entropy increase after mixing: 0.16992\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \u001b[31m####################RL Environment for Quantum Entanglement####################\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[32mInitialized environment with parameters: {'NS': 8, 'LA': 4, 'GAMMA': 4, 'K': 4, 'MAX_STEPS_PER_EPISODE': 2, 'NH': 256, 'DIM_A': 16, 'LB': 4, 'DIM_B': 16}\u001b[0m\n",
      "09_06_2025_13-10_00 [INFO] \t->\u001b[34mInitializing the environment...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gamma                               = 4\n",
    "actions_per_pair                    = 4\n",
    "ns                                  = 8\n",
    "la                                  = ns // 2\n",
    "# ─── Configuration ──────────────────────────────────────────────────────────────\n",
    "config = {\n",
    "    # ── Reproducibility ─────────────────────────────────────────────────────────\n",
    "    \"SEED\"                          : 42,\n",
    "\n",
    "    # ── Environment parameters ──────────────────────────────────────────────────\n",
    "    \"ENV\": {\n",
    "        \"NS\"                        : ns,                   # number of qubits in the system\n",
    "        \"LA\"                        : la,                   # number of qubits in subsystem A (log2 of dim_a)\n",
    "        \"GAMMA\"                     : gamma,                # number of coefficients (Gamma) - how many states do we mix\n",
    "        \"K\"                         : actions_per_pair,     # number of discrete Givens angles per pair\n",
    "        \"MAX_STEPS_PER_EPISODE\"     : max(1, gamma // 2),   # maximum number of steps per episode\n",
    "    },\n",
    "\n",
    "    # ── Training loop ───────────────────────────────────────────────────────────\n",
    "    \"TRAIN\": {\n",
    "        \"NUM_UPDATES\"               : 50,                   # number of updates to perform\n",
    "        \"NUM_STEPS\"                 : 256,                   # number of steps to collect before updating the agent\n",
    "        \"UPDATE_EPOCHS\"             : 4,\n",
    "        \"MAX_GRAD_NORM\"             : 0.5,                   # maximum gradient norm for clipping\n",
    "        \"MINIBATCH_SIZE\"            : 32,                    # size of each minibatch\n",
    "    },\n",
    "\n",
    "    # ── PPO hyper‐parameters ─────────────────────────────────────────────────────\n",
    "    \"PPO\": {\n",
    "        \"LEARNING_RATE\"             : 1e-4,\n",
    "        \"CLIP_EPS\"                  : 0.2,\n",
    "        \"VF_COEF\"                   : 0.5,\n",
    "        \"ENT_COEF\"                  : 0.01,\n",
    "        \"GAE_LAMBDA\"                : 0.95,\n",
    "        \"GAMMA_DISCOUNT\"            : 0.99,\n",
    "        \"UPDATE_EPOCHS\"             : 4,        # Number of epochs to update the agent per batch\n",
    "        \"SEED\"                      : 42,       # Seed for reproducibility, special for the PPO agent\n",
    "    },\n",
    "}\n",
    "\n",
    "# Calculate derived parameters to ensure consistency\n",
    "config[\"ENV\"][\"NH\"]         = 2**config[\"ENV\"][\"NS\"]\n",
    "config[\"ENV\"][\"DIM_A\"]      = 2**config[\"ENV\"][\"LA\"]\n",
    "config[\"ENV\"][\"LB\"]         = config[\"ENV\"][\"NS\"] - config[\"ENV\"][\"LA\"]\n",
    "config[\"ENV\"][\"DIM_B\"]      = 2**config[\"ENV\"][\"LB\"]\n",
    "total_training_steps        = config[\"TRAIN\"][\"NUM_UPDATES\"] * config[\"TRAIN\"][\"UPDATE_EPOCHS\"] * (config[\"TRAIN\"][\"NUM_STEPS\"] // config[\"ENV\"][\"MAX_STEPS_PER_EPISODE\"])\n",
    "\n",
    "# ─── Initialize the environment ────────────────────────────────────────────────\n",
    "data_org_jax, data_mix_jax, entropy_values  = initialize_set_of_states(config[\"ENV\"][\"GAMMA\"], config[\"ENV\"][\"NS\"], config[\"ENV\"][\"DIM_A\"], config[\"ENV\"][\"DIM_B\"], config[\"ENV\"][\"NH\"])\n",
    "\n",
    "logger.title(\"RL Environment for Quantum Entanglement\", desired_size=80, fill='#', color='red')\n",
    "logger.info(f\"Initialized environment with parameters: {config['ENV']}\", lvl=1, color='green')\n",
    "\n",
    "# ─── Create the environment ───────────────────────────────────────────────────\n",
    "logger.info(\"Initializing the environment...\", lvl=1, color='blue')\n",
    "env = QuantumEntanglementEnv(\n",
    "    Gamma               = config[\"ENV\"][\"GAMMA\"],\n",
    "    la                  = config[\"ENV\"][\"LA\"],\n",
    "    org_states          = data_mix_jax,         # Use the mixed states for the environment as we want to get as close to the original states as possible\n",
    "    org_states_info     = entropy_values,\n",
    "    modify_org_states   = False,\n",
    "    K                   = config[\"ENV\"][\"K\"],   \n",
    "    max_steps           = config[\"ENV\"][\"MAX_STEPS_PER_EPISODE\"],   \n",
    "    reg_lambda_norm     = 0.1\n",
    ")\n",
    "\n",
    "ppo_config              = {**config[\"PPO\"], **config[\"TRAIN\"]}\n",
    "agent = PPOAgent(\n",
    "    obs_shape           = env.observation_space.shape,\n",
    "    action_dim          = env.action_space.n,\n",
    "    config              = ppo_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d9cd5a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_06_2025_13-10_01 [INFO] \t->\u001b[0m----------------------Sanity Check: Greedy One-Step Search----------------------\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t->\u001b[34mInitial Total Entropy: 7.59033\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 0: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 1: Entropy after action = 7.25314, Reward = 0.33719\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 2: Entropy after action = 7.22249, Reward = 0.36784\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 3: Entropy after action = 7.57764, Reward = 0.01269\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 4: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 5: Entropy after action = 7.25314, Reward = 0.33719\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 6: Entropy after action = 7.22249, Reward = 0.36784\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 7: Entropy after action = 7.57764, Reward = 0.01269\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 8: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 9: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 10: Entropy after action = 7.63343, Reward = -0.04310\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 11: Entropy after action = 7.64106, Reward = -0.05073\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 12: Entropy after action = 7.60354, Reward = -0.01321\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 13: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 14: Entropy after action = 7.63343, Reward = -0.04310\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 15: Entropy after action = 7.64106, Reward = -0.05073\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 16: Entropy after action = 7.60354, Reward = -0.01321\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 17: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 18: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 19: Entropy after action = 7.41165, Reward = 0.17868\u001b[0m\n",
      "09_06_2025_13-10_01 [INFO] \t\t\t->\u001b[32mAction 20: Entropy after action = 7.26835, Reward = 0.32198\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 21: Entropy after action = 7.46743, Reward = 0.12290\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 22: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 23: Entropy after action = 7.41165, Reward = 0.17868\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 24: Entropy after action = 7.26835, Reward = 0.32198\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 25: Entropy after action = 7.46743, Reward = 0.12290\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 26: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 27: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 28: Entropy after action = 7.56299, Reward = 0.02734\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 29: Entropy after action = 7.46161, Reward = 0.12872\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 30: Entropy after action = 7.48067, Reward = 0.10966\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 31: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 32: Entropy after action = 7.56299, Reward = 0.02734\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 33: Entropy after action = 7.46161, Reward = 0.12872\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 34: Entropy after action = 7.48067, Reward = 0.10966\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 35: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 36: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 37: Entropy after action = 7.68224, Reward = -0.09191\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 38: Entropy after action = 7.63086, Reward = -0.04053\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 39: Entropy after action = 7.53543, Reward = 0.05490\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 40: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 41: Entropy after action = 7.68224, Reward = -0.09191\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 42: Entropy after action = 7.63086, Reward = -0.04053\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 43: Entropy after action = 7.53543, Reward = 0.05490\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 44: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 45: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 46: Entropy after action = 7.64064, Reward = -0.05031\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 47: Entropy after action = 7.80329, Reward = -0.21296\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 48: Entropy after action = 7.76325, Reward = -0.17292\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 49: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 50: Entropy after action = 7.64064, Reward = -0.05031\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 51: Entropy after action = 7.80329, Reward = -0.21296\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 52: Entropy after action = 7.76325, Reward = -0.17292\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t\t->\u001b[32mAction 53: Entropy after action = 7.59048, Reward = -0.00015\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t->\u001b[32mBest possible one-step reward: 0.36784\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t->\u001b[32mAchieved with action: 2\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t->\u001b[32mSUCCESS: There are actions that immediately reduce entropy.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.sanity()  # Perform a sanity check to ensure the environment behaves as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "502ecf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_06_2025_13-10_02 [INFO] \t->\u001b[32mStarting training loop...\u001b[0m\n",
      "09_06_2025_13-10_02 [INFO] \t\t->\u001b[0mTotal updates planned: 50\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|\u001b[34m          \u001b[0m| 0/50 [00:19<?, ?update/s, avg_entropy=1.3904, avg_reward_per_step=-0.9995, episode_reward=-2.9984, init_avg_entropy=1.2714, init_avg_mixed_entropy=1.3904, max_state_entropy=1.7662, min_state_entropy=1.1481, steps=3]\n",
      "Training Progress:   0%|\u001b[34m          \u001b[0m| 0/50 [00:06<?, ?update/s, avg_entropy=1.8976, avg_reward_per_step=1.1675, episode_reward=2.3350, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|\u001b[34m▏         \u001b[0m| 1/50 [00:15<07:47,  9.54s/update, avg_entropy=1.9508, avg_reward_per_step=1.6324, episode_reward=3.2647, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|\u001b[34m▍         \u001b[0m| 2/50 [00:24<07:29,  9.37s/update, avg_entropy=1.8702, avg_reward_per_step=0.8311, episode_reward=1.6622, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.5859, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|\u001b[34m▌         \u001b[0m| 3/50 [00:33<07:16,  9.28s/update, avg_entropy=1.8976, avg_reward_per_step=0.3295, episode_reward=0.6589, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|\u001b[34m▊         \u001b[0m| 4/50 [00:42<07:04,  9.22s/update, avg_entropy=1.9942, avg_reward_per_step=0.7243, episode_reward=1.4486, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.9393, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|\u001b[34m█         \u001b[0m| 5/50 [00:52<06:53,  9.19s/update, avg_entropy=1.8976, avg_reward_per_step=0.6003, episode_reward=1.2005, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|\u001b[34m█▏        \u001b[0m| 6/50 [01:01<06:43,  9.18s/update, avg_entropy=1.9102, avg_reward_per_step=0.2827, episode_reward=0.5654, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|\u001b[34m█▍        \u001b[0m| 7/50 [01:10<06:33,  9.15s/update, avg_entropy=1.9084, avg_reward_per_step=0.9617, episode_reward=1.9234, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0567, min_state_entropy=1.7876, steps=2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|\u001b[34m█▌        \u001b[0m| 8/50 [01:19<06:23,  9.12s/update, avg_entropy=1.8944, avg_reward_per_step=0.8320, episode_reward=1.6641, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0522, min_state_entropy=1.7589, steps=2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|\u001b[34m█▊        \u001b[0m| 9/50 [01:28<06:13,  9.10s/update, avg_entropy=1.8976, avg_reward_per_step=1.6003, episode_reward=3.2005, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|\u001b[34m██        \u001b[0m| 10/50 [01:37<06:03,  9.09s/update, avg_entropy=1.8654, avg_reward_per_step=1.6428, episode_reward=3.2857, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.5199, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  22%|\u001b[34m██▏       \u001b[0m| 11/50 [01:46<05:54,  9.10s/update, avg_entropy=1.8976, avg_reward_per_step=1.1672, episode_reward=2.3344, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  24%|\u001b[34m██▍       \u001b[0m| 12/50 [01:55<05:45,  9.10s/update, avg_entropy=1.8702, avg_reward_per_step=2.1058, episode_reward=4.2116, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.5859, steps=2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  26%|\u001b[34m██▌       \u001b[0m| 13/50 [02:04<05:36,  9.11s/update, avg_entropy=1.8976, avg_reward_per_step=1.4035, episode_reward=2.8070, init_avg_entropy=1.7277, init_avg_mixed_entropy=1.8976, max_state_entropy=2.0363, min_state_entropy=1.7876, steps=2]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# 2) Learning Phase - update the agent with the collected transitions\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Convert list of transitions to a batched Transition object\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     transitions \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mx: jnp\u001b[38;5;241m.\u001b[39mstack(x), \u001b[38;5;241m*\u001b[39mstorage)\n\u001b[0;32m---> 60\u001b[0m     agent\u001b[38;5;241m.\u001b[39mlearn(transitions, obs)\n\u001b[1;32m     61\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     63\u001b[0m logger\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, desired_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[108], line 143\u001b[0m, in \u001b[0;36mPPOAgent.learn\u001b[0;34m(self, transitions, last_obs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (final_state, key), jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(jnp\u001b[38;5;241m.\u001b[39mmean, metrics)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# 3) Run update over all epochs\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Use lax.scan for the epoch loop as well, for JIT-compatibility\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m (final_train_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey), metrics  \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mscan(_update_epoch, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey), \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUPDATE_EPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state                        \u001b[38;5;241m=\u001b[39m final_train_state\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Return the mean metrics over the final epoch\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/loops.py:308\u001b[0m, in \u001b[0;36mscan\u001b[0;34m(f, init, xs, length, reverse, unroll, _split_transpose)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (init_flat, carry_avals, carry_avals_out, init_tree, in_flat, jaxpr,\n\u001b[1;32m    301\u001b[0m           consts, out_tree, out_tree_children, attrs_tracked)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# The carry input and output avals must match exactly. However, we want to account for\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# the case when init contains weakly-typed values (e.g. Python scalars), with avals that\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# may not match the output despite being compatible by virtue of their weak type.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# To do this, we compute the jaxpr in two passes: first with the raw inputs, and if\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# necessary, a second time with modified init values.\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m init_flat, carry_avals, carry_avals_out, init_tree, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m _create_jaxpr(init)\n\u001b[1;32m    309\u001b[0m new_init_flat, changed \u001b[38;5;241m=\u001b[39m _promote_weak_typed_inputs(init_flat, carry_avals, carry_avals_out)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed:\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/loops.py:281\u001b[0m, in \u001b[0;36mscan.<locals>._create_jaxpr\u001b[0;34m(init)\u001b[0m\n\u001b[1;32m    279\u001b[0m in_flat, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten((init, xs))\n\u001b[1;32m    280\u001b[0m carry_avals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_map(core\u001b[38;5;241m.\u001b[39mget_aval, init_flat))\n\u001b[0;32m--> 281\u001b[0m jaxpr, consts, out_tree, attrs_tracked \u001b[38;5;241m=\u001b[39m _initial_style_jaxpr_attrs(\n\u001b[1;32m    282\u001b[0m     f, in_tree, (\u001b[38;5;241m*\u001b[39mcarry_avals, \u001b[38;5;241m*\u001b[39mx_avals), debug_info\u001b[38;5;241m=\u001b[39mdbg_body)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmutable_array_checks\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    284\u001b[0m   _check_no_aliased_closed_over_refs(dbg_body, (\u001b[38;5;241m*\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;241m*\u001b[39mconsts), in_flat)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/common.py:77\u001b[0m, in \u001b[0;36m_initial_style_jaxpr_attrs\u001b[0;34m(fun, in_tree, in_avals, debug_info)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initial_style_jaxpr_attrs\u001b[39m(fun: Callable,\n\u001b[1;32m     74\u001b[0m                                in_tree: PyTreeDef,\n\u001b[1;32m     75\u001b[0m                                in_avals: Sequence[core\u001b[38;5;241m.\u001b[39mAbstractValue],\n\u001b[1;32m     76\u001b[0m                                debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo):\n\u001b[0;32m---> 77\u001b[0m   jaxpr, consts, out_tree, attrs_tracked \u001b[38;5;241m=\u001b[39m _initial_style_open_jaxpr(\n\u001b[1;32m     78\u001b[0m       fun, in_tree, in_avals, debug_info)\n\u001b[1;32m     79\u001b[0m   closed_jaxpr \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mclose_jaxpr(pe\u001b[38;5;241m.\u001b[39mconvert_constvars_jaxpr(jaxpr))\n\u001b[1;32m     80\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m closed_jaxpr, consts, out_tree, attrs_tracked\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/common.py:59\u001b[0m, in \u001b[0;36m_initial_style_open_jaxpr\u001b[0;34m(fun, in_tree, in_avals, debug_info)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@weakref_lru_cache\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initial_style_open_jaxpr\u001b[39m(fun: Callable,\n\u001b[1;32m     53\u001b[0m                               in_tree: PyTreeDef,\n\u001b[1;32m     54\u001b[0m                               in_avals: Sequence[core\u001b[38;5;241m.\u001b[39mAbstractValue],\n\u001b[1;32m     55\u001b[0m                               debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo):\n\u001b[1;32m     56\u001b[0m   wrapped_fun, out_tree \u001b[38;5;241m=\u001b[39m api_util\u001b[38;5;241m.\u001b[39mflatten_fun_nokwargs(\n\u001b[1;32m     57\u001b[0m       lu\u001b[38;5;241m.\u001b[39mwrap_init(fun, debug_info\u001b[38;5;241m=\u001b[39mdebug_info),\n\u001b[1;32m     58\u001b[0m       in_tree)\n\u001b[0;32m---> 59\u001b[0m   jaxpr, _, consts, attrs_tracked \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mtrace_to_jaxpr_dynamic(\n\u001b[1;32m     60\u001b[0m       wrapped_fun, in_avals)\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jaxpr, consts, out_tree(), attrs_tracked\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:2223\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, keep_inputs)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2222\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m-> 2223\u001b[0m     ans \u001b[38;5;241m=\u001b[39m fun\u001b[38;5;241m.\u001b[39mcall_wrapped(\u001b[38;5;241m*\u001b[39min_tracers)\n\u001b[1;32m   2225\u001b[0m   out_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_jaxpr_tracer, ans)\n\u001b[1;32m   2226\u001b[0m   _check_no_returned_refs(fun\u001b[38;5;241m.\u001b[39mdebug_info, out_tracers)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:211\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_transformed(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39mpy_args)\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:402\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 402\u001b[0m   ans \u001b[38;5;241m=\u001b[39m _fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    403\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[1;32m    404\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:340\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    339\u001b[0m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[0;32m--> 340\u001b[0m  pgle_profiler) \u001b[38;5;241m=\u001b[39m _python_pjit_helper(fun, jit_info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    342\u001b[0m maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    343\u001b[0m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    344\u001b[0m     jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes,\n\u001b[1;32m    345\u001b[0m     pgle_profiler)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:178\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_pjit_helper\u001b[39m(fun: Callable, jit_info: PjitInfo, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 178\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m _infer_params(fun, jit_info, args, kwargs)\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args_flat:\n\u001b[1;32m    181\u001b[0m     dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:716\u001b[0m, in \u001b[0;36m_infer_params\u001b[0;34m(fun, ji, args, kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m (_internal_use_concrete_mesh(phys_mesh),\n\u001b[1;32m    714\u001b[0m         mesh_lib\u001b[38;5;241m.\u001b[39muse_abstract_mesh(phys_mesh\u001b[38;5;241m.\u001b[39mabstract_mesh)):\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _infer_params_internal(fun, ji, args, kwargs)\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _infer_params_internal(fun, ji, args, kwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:739\u001b[0m, in \u001b[0;36m_infer_params_internal\u001b[0;34m(fun, ji, args, kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m entry \u001b[38;5;241m=\u001b[39m _infer_params_cached(fun, ji, signature, avals, ctx_mesh)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mpjit_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m   p, args_flat \u001b[38;5;241m=\u001b[39m _infer_params_impl(\n\u001b[1;32m    740\u001b[0m       fun, ji, ctx_mesh, dbg, args, kwargs, in_avals\u001b[38;5;241m=\u001b[39mavals)\n\u001b[1;32m    741\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mattrs_tracked:  \u001b[38;5;66;03m# if attrs, don't populate the cache\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p, p\u001b[38;5;241m.\u001b[39mconsts \u001b[38;5;241m+\u001b[39m args_flat\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:636\u001b[0m, in \u001b[0;36m_infer_params_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    629\u001b[0m in_shardings_flat, in_layouts_flat \u001b[38;5;241m=\u001b[39m _process_in_axis_resources(\n\u001b[1;32m    630\u001b[0m     in_shardings_treedef, in_shardings_leaves,\n\u001b[1;32m    631\u001b[0m     ji\u001b[38;5;241m.\u001b[39min_layouts_treedef, ji\u001b[38;5;241m.\u001b[39min_layouts_leaves,\n\u001b[1;32m    632\u001b[0m     in_avals, in_tree, flat_fun\u001b[38;5;241m.\u001b[39mdebug_info, device_or_backend_set, have_kwargs)\n\u001b[1;32m    634\u001b[0m attr_token \u001b[38;5;241m=\u001b[39m _attr_cache_index(flat_fun, in_type)\n\u001b[0;32m--> 636\u001b[0m jaxpr, consts, out_avals, attrs_tracked \u001b[38;5;241m=\u001b[39m _create_pjit_jaxpr(\n\u001b[1;32m    637\u001b[0m     flat_fun, in_type, attr_token, IgnoreKey(ji\u001b[38;5;241m.\u001b[39minline))\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmutable_array_checks\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    640\u001b[0m   _check_no_aliased_closed_over_refs(dbg, (\u001b[38;5;241m*\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;241m*\u001b[39mconsts), explicit_args)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:477\u001b[0m, in \u001b[0;36mcache.<locals>.memoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_explain \u001b[38;5;241m:=\u001b[39m explain \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mexplain_cache_misses\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    476\u001b[0m   start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 477\u001b[0m ans \u001b[38;5;241m=\u001b[39m call(fun, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_explain:\n\u001b[1;32m    479\u001b[0m   explain(fun, cache \u001b[38;5;129;01mis\u001b[39;00m new_cache, cache, key, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:1441\u001b[0m, in \u001b[0;36m_create_pjit_jaxpr\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     attrs_tracked \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1441\u001b[0m     jaxpr, global_out_avals, consts, attrs_tracked \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mtrace_to_jaxpr_dynamic(\n\u001b[1;32m   1442\u001b[0m         fun, in_type)\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;66;03m# assert attr_data is sentinel or attr_data matches attrs_tracked\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_key_reuse\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m   1446\u001b[0m   \u001b[38;5;66;03m# Import here to avoid circular imports\u001b[39;00m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:2223\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, keep_inputs)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2222\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m-> 2223\u001b[0m     ans \u001b[38;5;241m=\u001b[39m fun\u001b[38;5;241m.\u001b[39mcall_wrapped(\u001b[38;5;241m*\u001b[39min_tracers)\n\u001b[1;32m   2225\u001b[0m   out_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_jaxpr_tracer, ans)\n\u001b[1;32m   2226\u001b[0m   _check_no_returned_refs(fun\u001b[38;5;241m.\u001b[39mdebug_info, out_tracers)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:211\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_transformed(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/api_util.py:288\u001b[0m, in \u001b[0;36m_argnums_partial\u001b[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(fixed_args_)\u001b[38;5;241m.\u001b[39mval \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/api_util.py:73\u001b[0m, in \u001b[0;36mflatten_fun\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_fun\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     71\u001b[0m                 in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     72\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 73\u001b[0m   ans \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39mpy_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpy_kwargs)\n\u001b[1;32m     74\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     75\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:402\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 402\u001b[0m   ans \u001b[38;5;241m=\u001b[39m _fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    403\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[1;32m    404\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[108], line 136\u001b[0m, in \u001b[0;36mPPOAgent.learn.<locals>._update_epoch\u001b[0;34m(carry, _)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_state, metrics\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Scan over all minibatches to update and collect metrics\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m final_state, metrics \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mscan(_update_minibatch, train_state, batch_data)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Return the updated state and the mean metrics for this epoch\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (final_state, key), jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(jnp\u001b[38;5;241m.\u001b[39mmean, metrics)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/loops.py:308\u001b[0m, in \u001b[0;36mscan\u001b[0;34m(f, init, xs, length, reverse, unroll, _split_transpose)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (init_flat, carry_avals, carry_avals_out, init_tree, in_flat, jaxpr,\n\u001b[1;32m    301\u001b[0m           consts, out_tree, out_tree_children, attrs_tracked)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# The carry input and output avals must match exactly. However, we want to account for\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# the case when init contains weakly-typed values (e.g. Python scalars), with avals that\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# may not match the output despite being compatible by virtue of their weak type.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# To do this, we compute the jaxpr in two passes: first with the raw inputs, and if\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# necessary, a second time with modified init values.\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m init_flat, carry_avals, carry_avals_out, init_tree, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m _create_jaxpr(init)\n\u001b[1;32m    309\u001b[0m new_init_flat, changed \u001b[38;5;241m=\u001b[39m _promote_weak_typed_inputs(init_flat, carry_avals, carry_avals_out)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed:\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/loops.py:281\u001b[0m, in \u001b[0;36mscan.<locals>._create_jaxpr\u001b[0;34m(init)\u001b[0m\n\u001b[1;32m    279\u001b[0m in_flat, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten((init, xs))\n\u001b[1;32m    280\u001b[0m carry_avals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_map(core\u001b[38;5;241m.\u001b[39mget_aval, init_flat))\n\u001b[0;32m--> 281\u001b[0m jaxpr, consts, out_tree, attrs_tracked \u001b[38;5;241m=\u001b[39m _initial_style_jaxpr_attrs(\n\u001b[1;32m    282\u001b[0m     f, in_tree, (\u001b[38;5;241m*\u001b[39mcarry_avals, \u001b[38;5;241m*\u001b[39mx_avals), debug_info\u001b[38;5;241m=\u001b[39mdbg_body)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmutable_array_checks\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    284\u001b[0m   _check_no_aliased_closed_over_refs(dbg_body, (\u001b[38;5;241m*\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;241m*\u001b[39mconsts), in_flat)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/common.py:77\u001b[0m, in \u001b[0;36m_initial_style_jaxpr_attrs\u001b[0;34m(fun, in_tree, in_avals, debug_info)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initial_style_jaxpr_attrs\u001b[39m(fun: Callable,\n\u001b[1;32m     74\u001b[0m                                in_tree: PyTreeDef,\n\u001b[1;32m     75\u001b[0m                                in_avals: Sequence[core\u001b[38;5;241m.\u001b[39mAbstractValue],\n\u001b[1;32m     76\u001b[0m                                debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo):\n\u001b[0;32m---> 77\u001b[0m   jaxpr, consts, out_tree, attrs_tracked \u001b[38;5;241m=\u001b[39m _initial_style_open_jaxpr(\n\u001b[1;32m     78\u001b[0m       fun, in_tree, in_avals, debug_info)\n\u001b[1;32m     79\u001b[0m   closed_jaxpr \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mclose_jaxpr(pe\u001b[38;5;241m.\u001b[39mconvert_constvars_jaxpr(jaxpr))\n\u001b[1;32m     80\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m closed_jaxpr, consts, out_tree, attrs_tracked\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/lax/control_flow/common.py:59\u001b[0m, in \u001b[0;36m_initial_style_open_jaxpr\u001b[0;34m(fun, in_tree, in_avals, debug_info)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;129m@weakref_lru_cache\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initial_style_open_jaxpr\u001b[39m(fun: Callable,\n\u001b[1;32m     53\u001b[0m                               in_tree: PyTreeDef,\n\u001b[1;32m     54\u001b[0m                               in_avals: Sequence[core\u001b[38;5;241m.\u001b[39mAbstractValue],\n\u001b[1;32m     55\u001b[0m                               debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo):\n\u001b[1;32m     56\u001b[0m   wrapped_fun, out_tree \u001b[38;5;241m=\u001b[39m api_util\u001b[38;5;241m.\u001b[39mflatten_fun_nokwargs(\n\u001b[1;32m     57\u001b[0m       lu\u001b[38;5;241m.\u001b[39mwrap_init(fun, debug_info\u001b[38;5;241m=\u001b[39mdebug_info),\n\u001b[1;32m     58\u001b[0m       in_tree)\n\u001b[0;32m---> 59\u001b[0m   jaxpr, _, consts, attrs_tracked \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mtrace_to_jaxpr_dynamic(\n\u001b[1;32m     60\u001b[0m       wrapped_fun, in_avals)\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jaxpr, consts, out_tree(), attrs_tracked\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:2223\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, keep_inputs)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2222\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m-> 2223\u001b[0m     ans \u001b[38;5;241m=\u001b[39m fun\u001b[38;5;241m.\u001b[39mcall_wrapped(\u001b[38;5;241m*\u001b[39min_tracers)\n\u001b[1;32m   2225\u001b[0m   out_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_jaxpr_tracer, ans)\n\u001b[1;32m   2226\u001b[0m   _check_no_returned_refs(fun\u001b[38;5;241m.\u001b[39mdebug_info, out_tracers)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:211\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_transformed(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39mpy_args)\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/linear_util.py:402\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 402\u001b[0m   ans \u001b[38;5;241m=\u001b[39m _fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    403\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[1;32m    404\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[108], line 132\u001b[0m, in \u001b[0;36mPPOAgent.learn.<locals>._update_epoch.<locals>._update_minibatch\u001b[0;34m(state, minibatch)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_minibatch\u001b[39m(state, minibatch):\n\u001b[1;32m    131\u001b[0m     (loss, metrics), grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(state\u001b[38;5;241m.\u001b[39mparams, minibatch)\n\u001b[0;32m--> 132\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mapply_gradients(grads\u001b[38;5;241m=\u001b[39mgrads)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_state, metrics\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/flax/training/train_state.py:103\u001b[0m, in \u001b[0;36mTrainState.apply_gradients\u001b[0;34m(self, grads, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m   grads_with_opt \u001b[38;5;241m=\u001b[39m grads\n\u001b[1;32m    101\u001b[0m   params_with_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m--> 103\u001b[0m updates, new_opt_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtx\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    104\u001b[0m   grads_with_opt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, params_with_opt\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m new_params_with_opt \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params_with_opt, updates)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# As implied by the OWG name, the gradients are used directly to update the\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# parameters.\u001b[39;00m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/optax/transforms/_combining.py:75\u001b[0m, in \u001b[0;36mchain.<locals>.update_fn\u001b[0;34m(updates, state, params, **extra_args)\u001b[0m\n\u001b[1;32m     73\u001b[0m new_state \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(state, update_fns):\n\u001b[0;32m---> 75\u001b[0m   updates, new_s \u001b[38;5;241m=\u001b[39m fn(updates, s, params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args)\n\u001b[1;32m     76\u001b[0m   new_state\u001b[38;5;241m.\u001b[39mappend(new_s)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updates, \u001b[38;5;28mtuple\u001b[39m(new_state)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/optax/transforms/_combining.py:75\u001b[0m, in \u001b[0;36mchain.<locals>.update_fn\u001b[0;34m(updates, state, params, **extra_args)\u001b[0m\n\u001b[1;32m     73\u001b[0m new_state \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(state, update_fns):\n\u001b[0;32m---> 75\u001b[0m   updates, new_s \u001b[38;5;241m=\u001b[39m fn(updates, s, params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args)\n\u001b[1;32m     76\u001b[0m   new_state\u001b[38;5;241m.\u001b[39mappend(new_s)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updates, \u001b[38;5;28mtuple\u001b[39m(new_state)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/optax/_src/base.py:333\u001b[0m, in \u001b[0;36mwith_extra_args_support.<locals>.update\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(updates, state, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m extra_args\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tx\u001b[38;5;241m.\u001b[39mupdate(updates, state, params)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/optax/_src/transform.py:467\u001b[0m, in \u001b[0;36mscale.<locals>.update_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fn\u001b[39m(updates, state, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    466\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m params\n\u001b[0;32m--> 467\u001b[0m   updates \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m g: step_size \u001b[38;5;241m*\u001b[39m g, updates)\n\u001b[1;32m    468\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m updates, state\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/tree.py:155\u001b[0m, in \u001b[0;36mmap\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(f: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any],\n\u001b[1;32m    116\u001b[0m         tree: Any,\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;241m*\u001b[39mrest: Any,\n\u001b[1;32m    118\u001b[0m         is_leaf: Callable[[Any], \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tree_util\u001b[38;5;241m.\u001b[39mtree_map(f, tree, \u001b[38;5;241m*\u001b[39mrest, is_leaf\u001b[38;5;241m=\u001b[39mis_leaf)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/tree_util.py:358\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    356\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    357\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/tree_util.py:358\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    356\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    357\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/optax/_src/transform.py:467\u001b[0m, in \u001b[0;36mscale.<locals>.update_fn.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fn\u001b[39m(updates, state, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    466\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m params\n\u001b[0;32m--> 467\u001b[0m   updates \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m g: step_size \u001b[38;5;241m*\u001b[39m g, updates)\n\u001b[1;32m    468\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m updates, state\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1060\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maval, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:579\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 579\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/numpy/ufunc_api.py:180\u001b[0m, in \u001b[0;36mufunc.__call__\u001b[0;34m(self, out, where, *args)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__static_props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_vectorized\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call(\u001b[38;5;241m*\u001b[39margs)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:340\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    339\u001b[0m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[0;32m--> 340\u001b[0m  pgle_profiler) \u001b[38;5;241m=\u001b[39m _python_pjit_helper(fun, jit_info, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    342\u001b[0m maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    343\u001b[0m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    344\u001b[0m     jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes,\n\u001b[1;32m    345\u001b[0m     pgle_profiler)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:193\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m   out_flat, compiled, profiler \u001b[38;5;241m=\u001b[39m _pjit_call_impl_python(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m pjit_p\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    194\u001b[0m   compiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/core.py:496\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    495\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 496\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_true_bind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/core.py:512\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    510\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_with_trace(prev_trace, args, params)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    514\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/core.py:517\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 517\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mprocess_primitive(\u001b[38;5;28mself\u001b[39m, args, params)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:1971\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m   1969\u001b[0m jaxpr_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_jaxpr_tracer, tracers)\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive \u001b[38;5;129;01min\u001b[39;00m custom_staging_rules:\n\u001b[0;32m-> 1971\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m custom_staging_rules[primitive](\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mjaxpr_tracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_process_primitive(primitive, jaxpr_tracers, params)\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/pjit.py:1927\u001b[0m, in \u001b[0;36mpjit_staging_rule\u001b[0;34m(trace, *args, **params)\u001b[0m\n\u001b[1;32m   1924\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39meval_jaxpr(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr, jaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   1925\u001b[0m                                     propagate_source_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1926\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pe\u001b[38;5;241m.\u001b[39minline_jaxpr_into_trace(\n\u001b[1;32m   1928\u001b[0m         trace, jaxpr\u001b[38;5;241m.\u001b[39mjaxpr, jaxpr\u001b[38;5;241m.\u001b[39mconsts, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1930\u001b[0m jaxpr \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaxpr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdynamic_shapes\u001b[38;5;241m.\u001b[39mvalue:\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:2627\u001b[0m, in \u001b[0;36minline_jaxpr_into_trace\u001b[0;34m(trace, jaxpr, consts, *arg_tracers)\u001b[0m\n\u001b[1;32m   2625\u001b[0m src \u001b[38;5;241m=\u001b[39m source_info_util\u001b[38;5;241m.\u001b[39mcurrent()\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eqn \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39meqns:\n\u001b[0;32m-> 2627\u001b[0m   invars \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Literal) \u001b[38;5;28;01melse\u001b[39;00m env[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39minvars]\n\u001b[1;32m   2628\u001b[0m   outvars \u001b[38;5;241m=\u001b[39m [Var(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39moutvars]\n\u001b[1;32m   2629\u001b[0m   src_ \u001b[38;5;241m=\u001b[39m (src \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39msource_info\u001b[38;5;241m.\u001b[39mname_stack \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m           src\u001b[38;5;241m.\u001b[39mreplace(name_stack\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mname_stack \u001b[38;5;241m+\u001b[39m eqn\u001b[38;5;241m.\u001b[39msource_info\u001b[38;5;241m.\u001b[39mname_stack))\n",
      "File \u001b[0;32m~/libraries/anaconda3/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:2627\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2625\u001b[0m src \u001b[38;5;241m=\u001b[39m source_info_util\u001b[38;5;241m.\u001b[39mcurrent()\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eqn \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39meqns:\n\u001b[0;32m-> 2627\u001b[0m   invars \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Literal) \u001b[38;5;28;01melse\u001b[39;00m env[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39minvars]\n\u001b[1;32m   2628\u001b[0m   outvars \u001b[38;5;241m=\u001b[39m [Var(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39moutvars]\n\u001b[1;32m   2629\u001b[0m   src_ \u001b[38;5;241m=\u001b[39m (src \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39msource_info\u001b[38;5;241m.\u001b[39mname_stack \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m           src\u001b[38;5;241m.\u001b[39mreplace(name_stack\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mname_stack \u001b[38;5;241m+\u001b[39m eqn\u001b[38;5;241m.\u001b[39msource_info\u001b[38;5;241m.\u001b[39mname_stack))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ─── Training Loop ─────────────────────────────────────────────────────────────\n",
    "logger.info(\"Starting training loop...\", lvl=1, color='green')\n",
    "\n",
    "obs, info       = env.reset(seed=config[\"SEED\"])\n",
    "all_rewards     = []\n",
    "all_entropies   = []\n",
    "num_updates     = config[\"TRAIN\"][\"NUM_UPDATES\"]\n",
    "logger.info(f\"Total updates planned: {num_updates}\", lvl=2, color='purple')\n",
    "\n",
    "\n",
    "# ─── Learning Rate Schedule ────────────────────────────────────────────────────\n",
    "lr_schedule     = optax.warmup_cosine_decay_schedule(\n",
    "    init_value      =   0.0,\n",
    "    peak_value      =   1e-4,\n",
    "    warmup_steps    =   int(total_training_steps * 0.1), # Use 10% of steps to warm up\n",
    "    decay_steps     =   int(total_training_steps * 0.9)  # Use the rest to decay\n",
    ")\n",
    "config[\"PPO\"][\"LEARNING_RATE\"] = lr_schedule\n",
    "\n",
    "# Main training loop\n",
    "sys.stdout.flush()\n",
    "pbar = tqdm(total=num_updates, desc=\"Training Progress\", unit=\"update\", colour='blue')\n",
    "pbar.reset()\n",
    "for update in range(num_updates):\n",
    "    \n",
    "    # 1) Rollout Phase - collect transitions and store them\n",
    "    storage         = []\n",
    "    episode_reward  = 0.0\n",
    "    info            = {}\n",
    "    for ii in range(config[\"TRAIN\"][\"NUM_STEPS\"]):\n",
    "        # Get action, value, and log_prob from the agent\n",
    "        action, value, log_prob                         = agent.get_action(obs)\n",
    "\n",
    "        # Step the environment\n",
    "        next_obs, reward, terminated, truncated, info   = env.step(int(action))\n",
    "        done                                            = terminated or truncated\n",
    "        episode_reward                                 += reward\n",
    "    \n",
    "        # Store the transition in the storage\n",
    "        storage.append(Transition(done, action, value, reward, log_prob, obs))\n",
    "        obs = next_obs\n",
    "        if done:\n",
    "            pbar.set_postfix(\n",
    "                episode_reward        = f\"{episode_reward:.4f}\",\n",
    "                avg_reward_per_step   = f\"{(episode_reward / env.step_count):.4f}\",\n",
    "                avg_entropy           = f\"{(info['total_entropy'] / env.Gamma):.4f}\",\n",
    "                min_state_entropy     = f\"{info['min_entropy']:.4f}\",\n",
    "                max_state_entropy     = f\"{info['max_entropy']:.4f}\",\n",
    "                init_avg_entropy      = f\"{entropy_values['average']:.4f}\",\n",
    "                init_avg_mixed_entropy= f\"{entropy_values['average_mixed']:.4f}\",\n",
    "                steps                 = env.step_count\n",
    "            )\n",
    "            all_rewards.append(env.step_count * reward) # Simple proxy for episode return\n",
    "            all_entropies.append(info['total_entropy'])\n",
    "            obs, info = env.reset()\n",
    "    print(\"Y\")\n",
    "    # 2) Learning Phase - update the agent with the collected transitions\n",
    "    # Convert list of transitions to a batched Transition object\n",
    "    transitions = jax.tree.map(lambda *x: jnp.stack(x), *storage)\n",
    "    agent.learn(transitions, obs)\n",
    "    pbar.update(1)\n",
    "    \n",
    "logger.title(\"Training Complete\", desired_size=80, fill='#', color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c58d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantumEntanglementEnv' object has no attribute 'current_entropies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39mentropy_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Avg Entropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39mentropy_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_mixed\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Avg Mixed Entropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m entropies_final \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mcurrent_entropies\n\u001b[1;32m     11\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal entropies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentropies_final\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, lvl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmanifold mapping: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39morg_states_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmanifold_mp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, lvl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuantumEntanglementEnv' object has no attribute 'current_entropies'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Plotting Results\n",
    "fig, ax = Plotter.get_subplots(1, 2, figsize=(12, 5), sharex = True)\n",
    "ax[0].plot(np.array(all_entropies) / env.Gamma, lw = 0.5)  # Normalize by Gamma to get average entropy per state\n",
    "ax[0].set_title(\"Final Entanglement Entropy per Episode\")\n",
    "ax[0].set_xlabel(\"Episode\")\n",
    "ax[0].set_ylabel(\"Average Entanglement Entropy\")\n",
    "ax[0].axhline(y=entropy_values['average'], color='r', linestyle='--', label='Initial Avg Entropy')\n",
    "ax[0].axhline(y=entropy_values['average_mixed'], color='g', linestyle='--', label='Initial Avg Mixed Entropy')\n",
    "\n",
    "entropies_final = env.current_entropies\n",
    "logger.info(f\"Final entropies: {entropies_final}\", color='blue', lvl=1)\n",
    "logger.info(f\"Submanifold mapping: {env.org_states_info['submanifold_mp']}\", color='blue', lvl=1)\n",
    "for i, e in enumerate(entropies_final):\n",
    "    logger.info(f\"Original state {i}: Entropy = {entropy_values['original'][i]:.3f}, Mixed state {i}: Entropy = {entropy_values['mixed'][i]:.3f}\", color='blue', lvl=2)\n",
    "    ax[0].axhline(y=e, color = 'blue', linestyle=':', alpha=0.5, label=f'$\\\\Gamma_{i} = {e:.3f}$')\n",
    "ax[0].legend(frameon=True, loc='upper right')\n",
    "ax[0].set_yscale('log')  # Use logarithmic scale for better visibility of entropies\n",
    "\n",
    "ax[1].plot(np.array(all_rewards) - np.min(all_rewards), lw = 0.5)\n",
    "ax[1].set_title(\"Approximate Episode Rewards\")\n",
    "ax[1].set_xlabel(\"Episode\")\n",
    "ax[1].set_ylabel(\"Reward\")\n",
    "ax[1].set_yscale('log')  # Use logarithmic scale for better visibility of rewards\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6caca4",
   "metadata": {},
   "source": [
    "### Test the entanglement entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "389c8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entanglement_loss_coeff(coeffs):\n",
    "    new_state_unmixed = data_mix_jax @ coeffs\n",
    "    schmidt_values, _ = schmidt_jax(new_state_unmixed, config[\"ENV\"][\"DIM_A\"], config[\"ENV\"][\"DIM_B\"], use_eig=False)\n",
    "    entro             = vn_entropy_jax(schmidt_values)\n",
    "    return entro\n",
    "\n",
    "entanglement_loss_calculator_jit = jax.jit(entanglement_loss_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cd9b01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_06_2025_11-10_41 [INFO] \t\t->\u001b[32mTesting entanglement loss with uniform coefficients... Norm=1.00000\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t\t->\u001b[32mEntropy of the demixed state with uniform coefficients: 1.44903\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t\t->\u001b[32mOriginal entropy averaged with uniform probabilities: 1.2713723182678223\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t->\u001b[31mTesting entanglement loss with random coefficients... Norm=1.00000\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t\t->\u001b[31mEntropy of the demixed state with random coefficients: 1.31057\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t\t->\u001b[31mOriginal entropy averaged with random probabilities: 1.088201642036438\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! Test the entanglement loss function with equal coefficients\n",
    "# coefficients_uniform    = jnp.array([1] + [0] * (gamma - 1))\n",
    "coefficients_uniform    = jnp.ones(data_mix_jax.shape[1])\n",
    "coefficients_uniform_n  = jnp.linalg.norm(coefficients_uniform)\n",
    "coefficients_uniform    = coefficients_uniform / coefficients_uniform_n\n",
    "logger.info(f\"Testing entanglement loss with uniform coefficients... Norm={jnp.linalg.norm(coefficients_uniform):.5f}\", lvl=2, color='green')\n",
    "entanglement_loss_test  = entanglement_loss_calculator_jit(coefficients_uniform)\n",
    "logger.info(f\"Entropy of the demixed state with uniform coefficients: {entanglement_loss_test:.5f}\", lvl=3, color='green')\n",
    "logger.info(f\"Original entropy averaged with uniform probabilities: {np.dot(entropy_values['original'], coefficients_uniform**2)}\", lvl=3, color='green')\n",
    "\n",
    "coefficients_random     = jax.random.uniform(key = key, shape=(data_mix_jax.shape[1],))\n",
    "coefficients_random_n   = jnp.linalg.norm(coefficients_random)\n",
    "coefficients_random     = coefficients_random / coefficients_random_n\n",
    "logger.info(f\"Testing entanglement loss with random coefficients... Norm={jnp.linalg.norm(coefficients_random):.5f}\", lvl=2, color='red')\n",
    "entanglement_loss_test  = entanglement_loss_calculator_jit(coefficients_random)\n",
    "logger.info(f\"Entropy of the demixed state with random coefficients: {entanglement_loss_test:.5f}\", lvl=3, color='red')\n",
    "logger.info(f\"Original entropy averaged with random probabilities: {np.dot(entropy_values['original'], coefficients_random**2)}\", lvl=3, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b34a18a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09_06_2025_11-10_41 [INFO] \t\t->\u001b[0mEntropy distribution: mean=1.40196, std=0.23165\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t->\u001b[34mMinimum entropy in distribution: 0.77177\u001b[0m\n",
      "09_06_2025_11-10_41 [INFO] \t\t->\u001b[31mMaximum entropy in distribution: 2.04594\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xaddbc5130>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the distribution of the entanglement entropies\n",
    "n_samples = 500\n",
    "gamma     = data_mix_jax.shape[1]           # Number of coefficients (Gamma)\n",
    "docoeffs  = False\n",
    "dim_a     = config[\"ENV\"][\"DIM_A\"]\n",
    "dim_b     = config[\"ENV\"][\"DIM_B\"]\n",
    "ns        = config[\"ENV\"][\"NS\"]\n",
    "if docoeffs:\n",
    "    logger.info(f\"Using {gamma} coefficients for entanglement entropy distribution calculation.\", lvl=2, color='purple')\n",
    "    entropies = np.zeros(n_samples)         # Array to store entanglement entropies\n",
    "else:\n",
    "    entropies = np.zeros(gamma * n_samples) # Array to store entanglement entropies\n",
    "\n",
    "for i in range(n_samples):\n",
    "    if docoeffs:\n",
    "        coefficients    = np.random.normal(size=(gamma,)) + 1j * np.random.normal(size=(gamma,)) # Ensure complex coefficients\n",
    "        coefficients_n  = np.linalg.norm(coefficients)\n",
    "        coefficients    = coefficients / (coefficients_n + 1e-11)\n",
    "        entropies[i]    = entanglement_loss_calculator_jit(coefficients)\n",
    "    else:\n",
    "        haar_unitary    = jnp.array(QuadraticSelection.haar_random_unitary(gamma=gamma))\n",
    "        states          = data_mix_jax @ haar_unitary\n",
    "        for j in range(gamma):\n",
    "            schmidt, _                  = schmidt_jax(states[:, j], dim_a, dim_b, use_eig=False) \n",
    "            entropies[i * gamma + j]    = vn_entropy_jax(schmidt)\n",
    "logger.info(f\"Entropy distribution: mean={np.mean(entropies):.5f}, std={np.std(entropies):.5f}\", lvl=2, color='purple')\n",
    "logger.info(f\"Minimum entropy in distribution: {np.min(entropies):.5f}\", lvl=2, color='blue')\n",
    "logger.info(f\"Maximum entropy in distribution: {np.max(entropies):.5f}\", lvl=2, color='red')\n",
    "\n",
    "page_value              = EntropyPredictions.Mean.page(da = dim_a, db = dim_b)\n",
    "page_value_u1           = EntropyPredictions.Mean.page_u1(La = config[\"ENV\"][\"LA\"], Lb = config[\"ENV\"][\"LB\"], n = config[\"ENV\"][\"LA\"] / config[\"ENV\"][\"NS\"])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(entropies, bins=30, density=True, alpha=0.6, color='g')\n",
    "plt.xlabel('Entanglement Entropy')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Entanglement Entropies')\n",
    "plt.grid()\n",
    "plt.axvline(x = page_value, color='red',     linestyle='--', label='Page Value')\n",
    "plt.axvline(x = page_value_u1, color='orange', linestyle='--', label='Page Value U(1)')\n",
    "plt.axvline(x = entropy_values['minimum'], color='b',       linestyle='--', label='Minimal Entropy in original States')\n",
    "plt.axvline(x = entropy_values['maximum'], color='orange',  linestyle='--', label='Maximal Entropy in original States')\n",
    "plt.axvline(x = entropy_values['average'], color='purple',  linestyle='--', label='Average Entropy in original States')\n",
    "plt.axvline(x = entropy_values['maximum'], color='black',   linestyle='--', label='Maximal Entropy + log(gamma)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abf16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
