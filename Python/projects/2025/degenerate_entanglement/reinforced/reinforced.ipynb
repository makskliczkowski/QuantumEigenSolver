{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9afc39",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_06_2025_17-22_10 [INFO] Log file created: ./log/QES_03_06_2025_17-22_10.log\n",
      "03_06_2025_17-22_10 [INFO] Log level set to: info\n",
      "03_06_2025_17-22_10 [INFO] ############Global logger initialized.############\n",
      "03_06_2025_17-22_10 [INFO] JAX is not available. Using NumPy as the active backend.\n",
      "03_06_2025_17-22_10 [INFO] **************************************************\n",
      "03_06_2025_17-22_10 [INFO] Backend Configuration:\n",
      "03_06_2025_17-22_10 [INFO] \t\tNumPy Version: 2.1.3\n",
      "03_06_2025_17-22_10 [INFO] \t\tSciPy Version: 1.15.2\n",
      "03_06_2025_17-22_10 [INFO] \t\tJAX Version: Not Available\n",
      "03_06_2025_17-22_10 [INFO] \t\tActive Backend: numpy\n",
      "03_06_2025_17-22_10 [INFO] \t\t\tJAX Available: False\n",
      "03_06_2025_17-22_10 [INFO] \t\t\tDefault Seed: 42\n",
      "03_06_2025_17-22_10 [INFO] \t\tNumPy Backend Details:\n",
      "03_06_2025_17-22_10 [INFO] \t\t\t\tMain Module: numpy\n",
      "03_06_2025_17-22_10 [INFO] \t\t\t\tRandom Module: Generator\n",
      "03_06_2025_17-22_10 [INFO] \t\t\t\tSciPy Module: scipy\n",
      "03_06_2025_17-22_10 [INFO] \t\tActive Data Types:\n",
      "03_06_2025_17-22_10 [INFO] \t\t\t\tInteger Type: int64\n",
      "03_06_2025_17-22_10 [INFO] \t\t\t\tFloat Type: float64\n",
      "03_06_2025_17-22_10 [INFO] \t\t\t\tComplex Type: complex128\n",
      "03_06_2025_17-22_10 [INFO] \t\tHardware & Device Detection:\n",
      "03_06_2025_17-22_10 [INFO] \t\t\tCPU Cores: 8\n",
      "03_06_2025_17-22_10 [INFO] \t\tJAX Platform: Not Applicable\n",
      "03_06_2025_17-22_10 [INFO] \t\tJAX Devices Found: Not Applicable\n",
      "03_06_2025_17-22_10 [INFO] **************************************************\n",
      "\n",
      "\n",
      "\n",
      "03_06_2025_17-22_10 [INFO] Log file created: ./log/QES_03_06_2025_17-22_10.log\n",
      "03_06_2025_17-22_10 [INFO] Log level set to: info\n",
      "03_06_2025_17-22_10 [INFO] ############Global logger initialized.############\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"BACKEND\"] = \"numpy\"\n",
    "# Set JAX backend if necessary (often not needed explicitly)\n",
    "# os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\" # or \"gpu\", \"tpu\"\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in locals() else os.getcwd()\n",
    "for i in range(1, 5): # Check up to 4 levels up\n",
    "    dir_up = os.path.abspath(os.path.join(script_dir, *(['..'] * i)))\n",
    "    if dir_up not in sys.path:\n",
    "        sys.path.append(dir_up)\n",
    "\n",
    "# try to import the gymnasium package, this is used to create a custom environment for quantum vector optimization\n",
    "import gymnasium as gym\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "import distrax\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "from typing import Callable, Tuple, List, Optional, Union\n",
    "from flax.training.train_state import TrainState\n",
    "\n",
    "# common utilities for logging\n",
    "try:\n",
    "    from QES.general_python.common.flog import Logger, get_global_logger\n",
    "    from QES.general_python.common.directories import Directories\n",
    "    from QES.Algebra.hamil_quadratic import QuadraticSelection\n",
    "    from extractors import vn_entropy_jax, schmidt_jax\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing custom modules (QES, extractors): {e}\")\n",
    "    print(\"Please ensure these modules are in the Python path and are JAX-compatible.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "#! Global Configuration & Initialization\n",
    "\n",
    "# For reproducibility\n",
    "master_seed     = np.random.randint(0, 2**32 - 1) \n",
    "# master_seed = 42 # Or set a fixed seed\n",
    "key             = jax.random.PRNGKey(master_seed)\n",
    "np.random.seed(master_seed)\n",
    "\n",
    "# Logger setup\n",
    "logger          = get_global_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e0b086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_06_2025_17-30_16 [INFO] Selected ORG file: /Users/makskliczkowski/Codes/QuantumEigenSolver/Python/Projects/2025/degenerate_entanglement/reinforced/data/org/ff,E=-0.26795,ns=12,gamma=26.npy (from 1 matches)\n",
      "03_06_2025_17-30_16 [INFO] Selected MIX file: /Users/makskliczkowski/Codes/QuantumEigenSolver/Python/Projects/2025/degenerate_entanglement/reinforced/data/mix/ff,E=-0.26795,ns=12,gamma=26.npy (should match ORG file naming convention)\n",
      "03_06_2025_17-30_16 [INFO] Loading original data from: /Users/makskliczkowski/Codes/QuantumEigenSolver/Python/Projects/2025/degenerate_entanglement/reinforced/data/org/ff,E=-0.26795,ns=12,gamma=26.npy\n",
      "03_06_2025_17-30_16 [INFO] Loading mixed data from: /Users/makskliczkowski/Codes/QuantumEigenSolver/Python/Projects/2025/degenerate_entanglement/reinforced/data/mix/ff,E=-0.26795,ns=12,gamma=26.npy\n",
      "03_06_2025_17-30_16 [INFO] \t->\u001b[32mLoaded data_org_jax with shape: (4096, 26)\u001b[0m\n",
      "03_06_2025_17-30_16 [INFO] \t->\u001b[32mLoaded data_mix_jax with shape: (4096, 26)\u001b[0m\n",
      "03_06_2025_17-30_16 [INFO] Calculating initial entanglement for a few original states (from data_org_jax):\n",
      "03_06_2025_17-30_16 [INFO] \u001b[34mOriginal State 0: Entropy = 1.69458\u001b[0m\n",
      "03_06_2025_17-30_16 [INFO] \u001b[34mOriginal State 1: Entropy = 2.87498\u001b[0m\n",
      "03_06_2025_17-30_16 [INFO] \u001b[34mOriginal State 2: Entropy = 2.77492\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 3: Entropy = 2.87498\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 4: Entropy = 2.22910\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 5: Entropy = 3.22612\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 6: Entropy = 2.87498\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 7: Entropy = 2.29439\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 8: Entropy = 2.73771\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[34mOriginal State 9: Entropy = 2.33740\u001b[0m\n",
      "03_06_2025_17-30_17 [INFO] \u001b[32mMinimal entropy found in original states: 1.69458\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "base_data_dir   = os.path.join(script_dir, 'data')\n",
    "directory_org   = Directories(os.path.join(base_data_dir, 'org'))\n",
    "directory_mix   = Directories(os.path.join(base_data_dir, 'mix'))\n",
    "\n",
    "# Check for data directories\n",
    "if not os.path.exists(directory_org.path):\n",
    "    logger.error(f\"Data directory not found: {directory_org.path_itself}\")\n",
    "    sys.exit(1)\n",
    "if not os.path.exists(directory_mix.path):\n",
    "    logger.error(f\"Data directory not found: {directory_mix.path_itself}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "files_org       = directory_org.list_files(filters=[lambda x: str(x).endswith('.npy')])\n",
    "files_mix       = directory_mix.list_files(filters=[lambda x: str(x).endswith('.npy')])\n",
    "\n",
    "# Parameters for data selection\n",
    "gamma_select    = 26\n",
    "ns              = 12\n",
    "dim_a           = 2**(ns // 2)\n",
    "dim_b           = 2**(ns // 2)\n",
    "org_nh          = 2**ns\n",
    "\n",
    "def get_random_matching_files(files_org_list, files_mix_list, gamma_val, ns_val):\n",
    "    # Filter org files\n",
    "    org_candidates = [str(f) for f in files_org_list if f'gamma={gamma_val}' in str(f) and f'ns={ns_val}' in str(f)]\n",
    "    if not org_candidates:\n",
    "        raise ValueError(f\"No ORG files found with gamma={gamma_val} and ns={ns_val}.\")\n",
    "    \n",
    "    selected_org_file = str(np.random.choice(org_candidates))\n",
    "    \n",
    "    # Try to find a corresponding mix file. This logic assumes a naming convention.\n",
    "    # The same name is there\n",
    "    selected_mix_file = selected_org_file.replace('org', 'mix')\n",
    "    logger.info(f\"Selected ORG file: {selected_org_file} (from {len(org_candidates)} matches)\")\n",
    "    logger.info(f\"Selected MIX file: {selected_mix_file} (should match ORG file naming convention)\")\n",
    "    return selected_org_file, selected_mix_file\n",
    "\n",
    "try:\n",
    "    random_file_org_path, random_file_mix_path = get_random_matching_files(files_org, files_mix, gamma_select, ns)\n",
    "    \n",
    "    logger.info(f\"Loading original data from: {random_file_org_path}\")\n",
    "    data_org        = np.load(random_file_org_path)\n",
    "    logger.info(f\"Loading mixed data from: {random_file_mix_path}\")\n",
    "    data_mix        = np.load(random_file_mix_path)\n",
    "    data_org_jax    = jnp.array(data_org)\n",
    "    data_mix_jax    = jnp.array(data_mix)\n",
    "    \n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    logger.error(f\"Error during data loading/selection: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "logger.info(f\"Loaded data_org_jax with shape: {data_org_jax.shape}\", lvl = 1, color = 'green')\n",
    "logger.info(f\"Loaded data_mix_jax with shape: {data_mix_jax.shape}\", lvl = 1, color = 'green')\n",
    "\n",
    "if data_mix_jax.shape[0] != org_nh:\n",
    "    logger.error(f\"Mismatch: data_mix_jax rows ({data_mix_jax.shape[0]}) != org_nh ({org_nh}).\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if data_mix_jax.shape[1] != gamma_select:\n",
    "    logger.error(f\"Mismatch: data_mix_jax columns ({data_mix_jax.shape[1]}) != gamma_select ({gamma_select}).\")\n",
    "    logger.error(\"The number of columns in mixed data (component states) must match gamma_select.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "logger.info(\"Calculating initial entanglement for a few original states (from data_org_jax):\")\n",
    "\n",
    "# Calculate entanglement for the first few original states\n",
    "num_states_to_check     = min(data_org_jax.shape[1], 10)\n",
    "minimal_entropy         = 1e10\n",
    "for i in range(num_states_to_check):\n",
    "    state               = data_org_jax[:, i]\n",
    "    state_norm_val      = jnp.linalg.norm(state)\n",
    "    if not jnp.isclose(state_norm_val, 1.0, atol=1e-6):\n",
    "        logger.warning(f\"Original state {i} norm is {state_norm_val:.4f}. Normalizing for entropy calculation.\", color='yellow', lvl=2)\n",
    "        state           = state / (state_norm_val + 1e-8)\n",
    "    \n",
    "    schmidt_values, _   = schmidt_jax(state, dim_a, dim_b, use_eig=False) # these already return schmidt values\n",
    "    entropy             = vn_entropy_jax(schmidt_values)\n",
    "    logger.info(f\"Original State {i}: Entropy = {entropy:.5f}\", color='blue')\n",
    "    minimal_entropy     = min(minimal_entropy, entropy)\n",
    "logger.info(f\"Minimal entropy found in original states: {minimal_entropy:.5f}\", color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31d29065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entanglement_loss_fn_for_env(coefficients: jnp.ndarray) -> jnp.ndarray:\n",
    "    # coefficients: complex vector of shape (gamma_select,)\n",
    "    # data_mix_jax: (org_nh, gamma_select), where each column is a basis state |psi_k_mix>\n",
    "    demixed_state               = jnp.tensordot(data_mix_jax, coefficients, axes=([1],[0])) # sum_k c_k * |psi_k_mix>\n",
    "    norm_demixed                = jnp.linalg.norm(demixed_state)\n",
    "    demixed_state_normalized    = demixed_state / (norm_demixed + 1e-8) # Ensure normalization for physical state\n",
    "    schmidt_values_demixed, _   = schmidt_jax(demixed_state_normalized, dim_a, dim_b, use_eig=False)\n",
    "    entropy_demixed             = vn_entropy_jax(schmidt_values_demixed**2)\n",
    "    return entropy_demixed\n",
    "\n",
    "entanglement_loss_calculator_jit = jax.jit(entanglement_loss_fn_for_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6caca4",
   "metadata": {},
   "source": [
    "### Test the entanglement entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e33e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_06_2025_17-30_18 [INFO] \t\t->\u001b[32mTesting entanglement loss with uniform coefficients... Norm=1.00000\u001b[0m\n",
      "03_06_2025_17-30_18 [INFO] \t\t\t->\u001b[32mEntropy of the demixed state with uniform coefficients: 2.56802\u001b[0m\n",
      "03_06_2025_17-30_18 [INFO] \t\t->\u001b[31mTesting entanglement loss with random coefficients... Norm=1.00000\u001b[0m\n",
      "03_06_2025_17-30_18 [INFO] \t\t\t->\u001b[31mEntropy of the demixed state with random coefficients: 2.51574\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! Test the entanglement loss function with equal coefficients\n",
    "coefficients_uniform    = jnp.ones(data_mix_jax.shape[1])\n",
    "coefficients_uniform_n  = jnp.linalg.norm(coefficients_uniform)\n",
    "coefficients_uniform    = coefficients_uniform / coefficients_uniform_n\n",
    "logger.info(f\"Testing entanglement loss with uniform coefficients... Norm={jnp.linalg.norm(coefficients_uniform):.5f}\", lvl=2, color='green')\n",
    "entanglement_loss_test  = entanglement_loss_calculator_jit(coefficients_uniform)\n",
    "logger.info(f\"Entropy of the demixed state with uniform coefficients: {entanglement_loss_test:.5f}\", lvl=3, color='green')\n",
    "\n",
    "coefficients_random     = jax.random.uniform(key = key, shape=(data_mix_jax.shape[1],))\n",
    "coefficients_random_n   = jnp.linalg.norm(coefficients_random)\n",
    "coefficients_random     = coefficients_random / coefficients_random_n\n",
    "logger.info(f\"Testing entanglement loss with random coefficients... Norm={jnp.linalg.norm(coefficients_random):.5f}\", lvl=2, color='red')\n",
    "entanglement_loss_test  = entanglement_loss_calculator_jit(coefficients_random)\n",
    "logger.info(f\"Entropy of the demixed state with random coefficients: {entanglement_loss_test:.5f}\", lvl=3, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47fc740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_06_2025_17-30_25 [INFO] \t\t->\u001b[0mEntropy distribution: mean=3.27843, std=0.07414\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x35a3c42c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the distribution of the entanglement entropies\n",
    "n_samples = 200\n",
    "gamma     = data_mix_jax.shape[1]           # Number of coefficients (Gamma)\n",
    "docoeffs  = False\n",
    "if docoeffs:\n",
    "    logger.info(f\"Using {gamma} coefficients for entanglement entropy distribution calculation.\", lvl=2, color='purple')\n",
    "    entropies = np.zeros(n_samples)         # Array to store entanglement entropies\n",
    "else:\n",
    "    entropies = np.zeros(gamma * n_samples) # Array to store entanglement entropies\n",
    "\n",
    "for i in range(n_samples):\n",
    "    if docoeffs:\n",
    "        coefficients    = np.random.normal(size=(gamma,)) + 1j * np.random.normal(size=(gamma,)) # Ensure complex coefficients\n",
    "        coefficients_n  = np.linalg.norm(coefficients)\n",
    "        coefficients    = coefficients / (coefficients_n + 1e-11)\n",
    "        entropies[i]    = entanglement_loss_calculator_jit(coefficients)\n",
    "    else:\n",
    "        haar_unitary    = jnp.array(QuadraticSelection.haar_random_unitary(gamma=gamma))\n",
    "        states          = data_mix_jax @ haar_unitary\n",
    "        for j in range(gamma):\n",
    "            schmidt, _                  = schmidt_jax(states[:, j], dim_a, dim_b, use_eig=False) \n",
    "            entropies[i * gamma + j]    = vn_entropy_jax(schmidt)\n",
    "            \n",
    "logger.info(f\"Entropy distribution: mean={np.mean(entropies):.5f}, std={np.std(entropies):.5f}\", lvl=2, color='purple')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(entropies, bins=30, density=True, alpha=0.6, color='g')\n",
    "plt.xlabel('Entanglement Entropy')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Entanglement Entropies')\n",
    "plt.grid()\n",
    "plt.axvline(x = np.log(2) * ns // 2 - 0.5, color='r', linestyle='--', label='Page Entropy')\n",
    "plt.axvline(x = minimal_entropy, color='b', linestyle='--', label='Minimal Entropy in original States')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38455dd7",
   "metadata": {},
   "source": [
    "## Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumVectorEnv(gym.Env):\n",
    "    \n",
    "    metadata = {'render_modes': ['human'], 'render_fps': 30}\n",
    "\n",
    "    def __init__(self, \n",
    "                gamma_dim           : int,\n",
    "                angle_list          : List[float],\n",
    "                loss_calculator     : Callable[[jnp.ndarray], jnp.ndarray],\n",
    "                reg_lambda_norm     : float = 0.1, initial_coeffs: jnp.ndarray = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if gamma_dim < 2: raise ValueError(\"Gamma dimension must be at least 2.\")\n",
    "        if not angle_list: raise ValueError(\"Angle list cannot be empty.\")\n",
    "        \n",
    "        self.gamma_dim = gamma_dim\n",
    "        self.angles = jnp.array(angle_list, dtype=jnp.float32)\n",
    "        self.num_angles = len(angle_list)\n",
    "        self.loss_calculator = loss_calculator # Function that returns scalar JAX array (e.g., entropy)\n",
    "        self.reg_lambda_norm = reg_lambda_norm\n",
    "        self.initial_coeffs_template = initial_coeffs\n",
    "\n",
    "        self.action_space = gymnasium.spaces.Discrete(int((gamma_dim * (gamma_dim - 1) // 2) * self.num_angles))\n",
    "        self.observation_space = gymnasium.spaces.Box(low=-1.0, high=1.0, shape=(2 * gamma_dim,), dtype=np.float32)\n",
    "\n",
    "        self.coeffs_state: jnp.ndarray = None # Stores the complex coefficient vector c\n",
    "        self.current_loss_value: jnp.ndarray = None\n",
    "        self.rng_internal = None # JAX PRNG key for this env instance\n",
    "\n",
    "    def reset(self, seed: int = None, options: Dict = None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        if seed is None: # Create a new seed if none provided\n",
    "            seed = np.random.randint(0, 2**32 - 1)\n",
    "        self.rng_internal = jax.random.PRNGKey(seed)\n",
    "\n",
    "        if self.initial_coeffs_template is not None:\n",
    "            coeffs = jnp.array(self.initial_coeffs_template, dtype=jnp.complex64)\n",
    "            if coeffs.shape != (self.gamma_dim,):\n",
    "                raise ValueError(f\"Initial coeffs shape {coeffs.shape} != ({self.gamma_dim},)\")\n",
    "            coeffs_norm = jnp.linalg.norm(coeffs)\n",
    "            if not jnp.isclose(coeffs_norm, 1.0):\n",
    "                logger.warning(f\"Provided initial coeffs norm is {coeffs_norm:.4f}. Normalizing.\")\n",
    "                coeffs = coeffs / (coeffs_norm + 1e-8)\n",
    "        else:\n",
    "            key_real, key_imag = jax.random.split(self.rng_internal)\n",
    "            c_real = jax.random.normal(key_real, (self.gamma_dim,))\n",
    "            c_imag = jax.random.normal(key_imag, (self.gamma_dim,))\n",
    "            coeffs = c_real + 1j * c_imag\n",
    "            coeffs = coeffs / (jnp.linalg.norm(coeffs) + 1e-8)\n",
    "        \n",
    "        self.coeffs_state = coeffs\n",
    "        self.current_loss_value = self.loss_calculator(self.coeffs_state)\n",
    "        \n",
    "        info = {'initial_loss': self.current_loss_value.item()}\n",
    "        return self._get_obs(), info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        idx_i, idx_j, angle_idx = self._decode_action(action)\n",
    "        theta_rot = self.angles[angle_idx]\n",
    "        \n",
    "        self.coeffs_state = self._apply_rotation(self.coeffs_state, idx_i, idx_j, theta_rot)\n",
    "        \n",
    "        current_norm_sq = jnp.sum(jnp.abs(self.coeffs_state)**2)\n",
    "        norm_penalty_val = jnp.abs(1.0 - current_norm_sq)\n",
    "        \n",
    "        # Renormalize coefficients to prevent drift, if desired, then penalty is less critical\n",
    "        # self.coeffs_state = self.coeffs_state / (jnp.sqrt(current_norm_sq) + 1e-8)\n",
    "        # norm_penalty_val = 0.0 # If re-normalizing state\n",
    "\n",
    "        self.current_loss_value = self.loss_calculator(self.coeffs_state) # This is the entanglement S_E\n",
    "        # Reward: we want to MINIMIZE S_E. So, reward = -S_E. Also penalize norm deviation.\n",
    "        reward = -self.current_loss_value - self.reg_lambda_norm * norm_penalty_val\n",
    "        \n",
    "        terminated = False # Episode is infinite horizon unless other conditions are set\n",
    "        truncated = False \n",
    "\n",
    "        info = {\n",
    "            'loss': self.current_loss_value.item(), \n",
    "            'norm_penalty': norm_penalty_val.item(),\n",
    "            'coeff_norm_sq': current_norm_sq.item()\n",
    "        }\n",
    "        return self._get_obs(), reward.item(), terminated, truncated, info\n",
    "\n",
    "    def _apply_rotation(self, c_vec: jnp.ndarray, i: int, j: int, theta: jnp.ndarray) -> jnp.ndarray:\n",
    "        ci, cj = c_vec[i], c_vec[j]\n",
    "        cos_t, sin_t = jnp.cos(theta), jnp.sin(theta)\n",
    "        \n",
    "        # SU(2) rotation on (ci, cj) subspace. This is a real rotation matrix.\n",
    "        # If complex phases are desired in rotation: R = [[cos(t), -e^(i*phi)sin(t)], [e^(-i*phi)sin(t), cos(t)]]\n",
    "        # For now, using the provided real rotation.\n",
    "        ci_new = cos_t * ci - sin_t * cj\n",
    "        cj_new = sin_t * ci + cos_t * cj\n",
    "        \n",
    "        return c_vec.at[i].set(ci_new).at[j].set(cj_new)\n",
    "\n",
    "    def _decode_action(self, action_flat: int) -> Tuple[int, int, int]:\n",
    "        pair_idx = action_flat // self.num_angles\n",
    "        angle_table_idx = action_flat % self.num_angles\n",
    "\n",
    "        current_pair_count = 0\n",
    "        for i in range(self.gamma_dim):\n",
    "            for j in range(i + 1, self.gamma_dim):\n",
    "                if current_pair_count == pair_idx:\n",
    "                    return i, j, angle_table_idx\n",
    "                current_pair_count += 1\n",
    "        raise ValueError(f\"Invalid action {action_flat} decoded to invalid pair_idx {pair_idx}\")\n",
    "\n",
    "    def _get_obs(self) -> np.ndarray: # Must return np.ndarray\n",
    "        obs_complex_flat = jnp.concatenate([jnp.real(self.coeffs_state), jnp.imag(self.coeffs_state)])\n",
    "        return np.array(obs_complex_flat, dtype=np.float32)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'human':\n",
    "            norm_sq = jnp.sum(jnp.abs(self.coeffs_state)**2).item()\n",
    "            loss_val_str = f\"{self.current_loss_value.item():.5f}\" if self.current_loss_value is not None else \"N/A\"\n",
    "            print(f\"Coeffs Norm^2: {norm_sq:.5f}, Loss (Entanglement): {loss_val_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f1bbcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/var/folders/7h/4tmv99_x2djdm97ys2h7mh5m0000gn/T/ipykernel_56017/1382171744.py:11: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  '''\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "non-default argument 'params' follows default argument",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 231\u001b[39m\n\u001b[32m    225\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m logits, value.squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m##################################\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m#! TrainState for PPO\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m##################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mPPOTrainState\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mTrainState\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_fn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m##################################\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m#! Utility functions for PPO\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m##################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/flax/struct.py:235\u001b[39m, in \u001b[36mPyTreeNode.__init_subclass__\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init_subclass__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m   \u001b[43mdataclass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/flax/struct.py:134\u001b[39m, in \u001b[36mdataclass\u001b[39m\u001b[34m(clz, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mfrozen\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs.keys():\n\u001b[32m    133\u001b[39m   kwargs[\u001b[33m'\u001b[39m\u001b[33mfrozen\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m data_clz = \u001b[43mdataclasses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclz\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    135\u001b[39m meta_fields = []\n\u001b[32m    136\u001b[39m data_fields = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/dataclasses.py:1256\u001b[39m, in \u001b[36mdataclass.<locals>.wrap\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_process_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsafe_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweakref_slot\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/dataclasses.py:1063\u001b[39m, in \u001b[36m_process_class\u001b[39m\u001b[34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[39m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m init:\n\u001b[32m   1059\u001b[39m     \u001b[38;5;66;03m# Does this class have a post-init function?\u001b[39;00m\n\u001b[32m   1060\u001b[39m     has_post_init = \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _POST_INIT_NAME)\n\u001b[32m   1062\u001b[39m     _set_new_attribute(\u001b[38;5;28mcls\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m__init__\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m                        \u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_init_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mstd_init_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mkw_only_init_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mhas_post_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# The name to use for the \"self\"\u001b[39;49;00m\n\u001b[32m   1069\u001b[39m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# param in __init__.  Use \"self\"\u001b[39;49;00m\n\u001b[32m   1070\u001b[39m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# if possible.\u001b[39;49;00m\n\u001b[32m   1071\u001b[39m \u001b[43m                                \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m__dataclass_self__\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mself\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mself\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mslots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1077\u001b[39m \u001b[38;5;66;03m# Get the fields as a list, and include only real fields.  This is\u001b[39;00m\n\u001b[32m   1078\u001b[39m \u001b[38;5;66;03m# used in all of the following methods.\u001b[39;00m\n\u001b[32m   1079\u001b[39m field_list = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields.values() \u001b[38;5;28;01mif\u001b[39;00m f._field_type \u001b[38;5;129;01mis\u001b[39;00m _FIELD]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/dataclasses.py:585\u001b[39m, in \u001b[36m_init_fn\u001b[39m\u001b[34m(fields, std_fields, kw_only_fields, frozen, has_post_init, self_name, globals, slots)\u001b[39m\n\u001b[32m    583\u001b[39m             seen_default = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m seen_default:\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnon-default argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    586\u001b[39m                             \u001b[33m'\u001b[39m\u001b[33mfollows default argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    588\u001b[39m \u001b[38;5;28mlocals\u001b[39m = {\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m__dataclass_type_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m__\u001b[39m\u001b[33m'\u001b[39m: f.type \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fields}\n\u001b[32m    589\u001b[39m \u001b[38;5;28mlocals\u001b[39m.update({\n\u001b[32m    590\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m__dataclass_HAS_DEFAULT_FACTORY__\u001b[39m\u001b[33m'\u001b[39m: _HAS_DEFAULT_FACTORY,\n\u001b[32m    591\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m__dataclass_builtins_object__\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mobject\u001b[39m,\n\u001b[32m    592\u001b[39m })\n",
      "\u001b[31mTypeError\u001b[39m: non-default argument 'params' follows default argument"
     ]
    }
   ],
   "source": [
    "\n",
    "class QuantumVectorEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A Gymnasium environment for optimizing a complex normalized vector using pairwise unitary rotations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  \n",
    "                gamma       : int,\n",
    "                angles      : list,\n",
    "                loss_fn     : Callable[[jnp.ndarray], float],\n",
    "                reg_lambda  : float = 10.0):\n",
    "        '''\n",
    "        Initializes the QuantumVectorEnv environment.\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "            gamma (int):\n",
    "                Dimension of the complex vector that constitutes the quantum states (in any basis, with a specific Hilbert space dimension).\n",
    "                The states are represented as complex vectors of size gamma, such that:\n",
    "                \\psi = \\sum _i c_i |\\phi _i \\rangle, where \\vec{c} \\in \\mathbb{C}^N, and \\sum _i |c_i|^2 = 1. \n",
    "                Also, |phi _i> = \\sum _k \\phi _i^k |k \\rangle, where \\phi _i^k are the basis states in the computational basis.\n",
    "            angles (list):\n",
    "                List of discrete rotation angles in radians.\n",
    "            loss_fn (Callable[[jnp.ndarray], float]):\n",
    "                A function that takes the current state as input and returns a scalar loss value. This is meant to be \n",
    "                an entanglement black-box that can take coefficients (\\Gamma-dimensional complex vector) and return a scalar loss value\n",
    "                based on combining the states in an arbitrary basis according to the coefficients.\n",
    "            reg_lambda (float):\n",
    "                Regularization strength for the norm penalty. The norm penalty is applied to encourage the state vector to remain normalized.\n",
    "                Default is 10.0.\n",
    "            norm_instead_of_penal (bool):\n",
    "                If True, the state is normalized instead of penalized. This means that the state will always remain normalized,\n",
    "                and the loss function will not include a norm penalty term. Default is False.\n",
    "        Raises:\n",
    "            ValueError: If gamma is less than 2 or angles is empty.\n",
    "\n",
    "        '''\n",
    "        if gamma < 2:\n",
    "            raise ValueError(\"Gamma must be at least 2 to allow for pairwise rotations.\")\n",
    "        \n",
    "        if not angles or not isinstance(angles, list) or not all(isinstance(angle, (int, float)) for angle in angles):\n",
    "            raise ValueError(\"Angles must be a non-empty list of numeric values (radians).\")\n",
    "        \n",
    "        #! Initialize the environment with the given parameters.\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gamma              = gamma                 # Dimension of the complex vector\n",
    "        self.angles             = jnp.array(angles)     # List of discrete angles that one can use to rotate the vector (in radians)\n",
    "        self.num_angles         = len(angles)\n",
    "        self.loss_fn            = loss_fn               # Black-box loss function\n",
    "        self.reg_lambda         = reg_lambda            # Regularization strength for the norm penalty\n",
    "\n",
    "        # action space is defined as the number of unique pairs (i, j) with i < j multiplied by the number of angles,\n",
    "        # it allows to choose a pair of indices (i, j) to apply a rotation and the angle of rotation\n",
    "        self.action_space       = gym.spaces.Discrete((gamma * (gamma - 1) // 2) * self.num_angles)\n",
    "        \n",
    "        # observation space is a flattened complex vector of size 2 * gamma (real and imaginary parts)\n",
    "        self.observation_space  = gym.spaces.Box(low=-1.0, high=1.0, shape=(2 * gamma,), dtype=np.float32) \n",
    "\n",
    "        self.state              = None\n",
    "        self.seed               = None\n",
    "        self.rng                = None\n",
    "        self.norm_inst_of_penal = False                 # Flag to indicate if the norm penalty is applied as an instance of the loss function\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, \n",
    "            seed    = None, \n",
    "            options = None):\n",
    "        '''\n",
    "        Resets the environment to an initial state. It creates a random normalized complex vector of size gamma.\n",
    "        \n",
    "        TODO: Implement options for resetting the environment, such as setting a specific initial state or parameters. \n",
    "        Allow for more flexibility in resetting the environment and add Haar randomization options.\n",
    "        \n",
    "        Parameters:\n",
    "            seed (int, optional):\n",
    "                Random seed for reproducibility. If None, a random seed is generated.\n",
    "            options (dict, optional):\n",
    "                Additional options for resetting the environment (not used in this implementation).\n",
    "        Returns:\n",
    "            Tuple of (observation, info):\n",
    "                - observation: The initial state of the environment as a flattened complex vector.\n",
    "                - info: An empty dictionary for additional information (not used in this implementation).\n",
    "        \n",
    "        '''\n",
    "        if seed is None:\n",
    "            self.seed = np.random.randint(0, 2**32)\n",
    "        else:\n",
    "            self.seed = seed\n",
    "        self.rng    = jax.random.PRNGKey(self.seed)\n",
    "        v_real      = jax.random.normal(self.rng, (self.gamma,)) # create a vector of real parts\n",
    "        v_imag      = jax.random.normal(self.rng, (self.gamma,)) # create a vector of imaginary parts \n",
    "        v           = v_real + 1j * v_imag\n",
    "        v          /= jnp.linalg.norm(v)\n",
    "        self.state  = v # make the state a normalized complex vector\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    #############################\n",
    "    #! Single step interaction with the environment\n",
    "    #############################    \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Decode the action to get indices and angle\n",
    "        i, j, theta_idx     = self._decode_action(action)\n",
    "        # Theta is the angle of rotation to apply\n",
    "        theta               = self.angles[theta_idx]\n",
    "        # Update the state by applying the rotation\n",
    "        self.state          = self._apply_rotation(self.state, i, j, theta)\n",
    "\n",
    "        # Compute the norm penalty\n",
    "        norm_penalty        = jnp.abs(1.0 - jnp.sum(jnp.abs(self.state) ** 2)) if (not self.norm_inst_of_penal) else 0.0\n",
    "        reward              = -self.loss_fn(self.state) - self.reg_lambda * norm_penalty\n",
    "        done                = False\n",
    "        \n",
    "        # Return the observation, reward, done flag, and additional info\n",
    "        return self._get_obs(), reward.item(), done, False, {}\n",
    "\n",
    "    #############################\n",
    "    #! Helper methods for the environment\n",
    "    #############################\n",
    "\n",
    "    def _apply_rotation(self, v: jnp.ndarray, i: int, j: int, theta: float) -> jnp.ndarray:\n",
    "        '''\n",
    "        Applies a pairwise rotation to the complex vector v at indices i and j using the angle theta.\n",
    "        The rotation is a real-valued SU(2) rotation in the 2D subspace spanned by the indices i and j.\n",
    "        \n",
    "        Parameters:\n",
    "            v (jnp.ndarray):\n",
    "                The complex vector to which the rotation is applied.\n",
    "            i (int):\n",
    "                The first index of the pair to apply the rotation.\n",
    "            j (int):\n",
    "                The second index of the pair to apply the rotation.\n",
    "            theta (float):\n",
    "                The angle of rotation in radians.\n",
    "        Returns:\n",
    "            jnp.ndarray:\n",
    "                The updated complex vector after applying the rotation.\n",
    "        '''\n",
    "        \n",
    "        # choose the indices i and j to apply the rotation\n",
    "        vi, vj      = v[i], v[j]\n",
    "        cos_theta   = jnp.cos(theta)\n",
    "        sin_theta   = jnp.sin(theta)\n",
    "\n",
    "        # Real-valued SU(2) rotation in the 2D subspace\n",
    "        vi_new      = cos_theta * vi - sin_theta * vj\n",
    "        vj_new      = sin_theta * vi + cos_theta * vj\n",
    "\n",
    "        v           = v.at[i].set(vi_new)\n",
    "        v           = v.at[j].set(vj_new)\n",
    "        return v\n",
    "\n",
    "    def _decode_action(self, action: int):\n",
    "        '''\n",
    "        Decodes the action index into the corresponding pair of indices (i, j) and angle index.\n",
    "        The action is a flat index that represents a unique pair of indices (i, j) with i < j, and an angle index.\n",
    "        The action space is defined as the number of unique pairs (i, j) with i < j multiplied by the number of angles.\n",
    "        \n",
    "        Parameters:\n",
    "            action (int):\n",
    "                The action index to decode.\n",
    "        Returns:\n",
    "            Tuple of (i, j, theta_idx):\n",
    "                - i (int): First index of the pair.\n",
    "                - j (int): Second index of the pair.\n",
    "                - theta_idx (int): Index of the angle to apply.\n",
    "        '''\n",
    "        # Decode the action into indices and angle index\n",
    "        ij_idx      = action // self.num_angles\n",
    "        theta_idx   = action % self.num_angles\n",
    "\n",
    "        # Map flat index to upper-triangle (i < j)\n",
    "        count       = 0\n",
    "        for i in range(self.N):\n",
    "            for j in range(i + 1, self.N):\n",
    "                if count == ij_idx:\n",
    "                    return i, j, theta_idx\n",
    "                count += 1\n",
    "        raise ValueError(\"Invalid action index\")\n",
    "\n",
    "    def _get_obs(self):\n",
    "        '''\n",
    "        Returns the current state as a flattened complex vector, concatenating the real and imaginary parts.\n",
    "        \n",
    "        Returns:\n",
    "            jnp.ndarray:\n",
    "                The current state as a flattened complex vector of size 2 * gamma (real and imaginary parts).\n",
    "        '''\n",
    "        return jnp.concatenate([jnp.real(self.state), jnp.imag(self.state)]).astype(jnp.float32)\n",
    "\n",
    "    def render(self):\n",
    "        print(\"State norm:\", jnp.sum(jnp.abs(self.state) ** 2))\n",
    "        print(\"State:\", self.state)\n",
    "\n",
    "##################################\n",
    "#! PPO Agent for QuantumVectorEnv\n",
    "##################################\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    action_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        '''\n",
    "        Defines a simple forward pass of the actor-critic model.\n",
    "        The model consists of two dense layers with tanh activation, followed by two output layers:\n",
    "        \n",
    "        - logits: Output layer for action probabilities (logits).\n",
    "        - value: Output layer for state value estimation.\n",
    "        Parameters:\n",
    "            x (jnp.ndarray):\n",
    "                Input tensor representing the state of the environment.\n",
    "        Returns:\n",
    "            Tuple of (logits, value):\n",
    "                - logits (jnp.ndarray): Output tensor representing action probabilities.\n",
    "                - value (jnp.ndarray): Output tensor representing state value estimation.\n",
    "        '''\n",
    "        x       = nn.Dense(128)(x)\n",
    "        x       = nn.tanh(x)\n",
    "        x       = nn.Dense(128)(x)\n",
    "        x       = nn.tanh(x)\n",
    "        logits  = nn.Dense(self.action_dim)(x)\n",
    "        value   = nn.Dense(1)(x)\n",
    "        return logits, value.squeeze(-1)\n",
    "\n",
    "##################################\n",
    "#! TrainState for PPO\n",
    "##################################\n",
    "\n",
    "class PPOTrainState(TrainState):\n",
    "    apply_fn: Callable = None\n",
    "\n",
    "##################################\n",
    "#! Utility functions for PPO\n",
    "##################################\n",
    "\n",
    "def select_action(params, apply_fn, obs, key):\n",
    "    \"\"\"\n",
    "    Selects an action based on the current policy and state observation.\n",
    "    \n",
    "    Parameters:\n",
    "        params: \n",
    "            The parameters of the actor-critic model.\n",
    "        apply_fn:\n",
    "            The function to apply the model to get logits and value.\n",
    "        obs:\n",
    "            The current state observation.\n",
    "        key:\n",
    "            JAX random key for sampling.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (action, log_prob, value):\n",
    "            - action: The selected action.\n",
    "            - log_prob: The log probability of the selected action.\n",
    "            - value: The estimated value of the current state.\n",
    "    \"\"\"\n",
    "    logits, value   = apply_fn({'params': params}, obs)\n",
    "    dist            = distrax.Categorical(logits=logits)\n",
    "    action          = dist.sample(seed=key)\n",
    "    log_prob        = dist.log_prob(action)\n",
    "    return action, log_prob, value\n",
    "\n",
    "def compute_gae(rewards, values, dones, gamma=0.99, lam=0.95):\n",
    "    \"\"\"\n",
    "    Computes Generalized Advantage Estimation (GAE) for Proximal Policy Optimization.\n",
    "    \n",
    "    Parameters:\n",
    "        rewards (array):\n",
    "            Array of rewards for each timestep\n",
    "        values (array):\n",
    "            Array of value estimates for each timestep (including next state)\n",
    "        dones (array):\n",
    "            Array of done flags for each timestep\n",
    "        gamma (float):\n",
    "            Discount factor for future rewards\n",
    "        lam (float):\n",
    "            Lambda parameter for GAE\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (advantages, returns):\n",
    "            - advantages: Calculated advantage values\n",
    "            - returns: Calculated returns (advantages + values)\n",
    "    \"\"\"\n",
    "    advantages  = []\n",
    "    gae         = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        delta   = rewards[t] + gamma * values[t+1] * (1 - dones[t]) - values[t]\n",
    "        gae     = delta + gamma * lam * (1 - dones[t]) * gae\n",
    "        advantages.insert(0, gae)\n",
    "    returns = advantages + values[:-1]\n",
    "    return jnp.array(advantages), jnp.array(returns)\n",
    "\n",
    "##################################\n",
    "#! PPO Loss Function\n",
    "##################################\n",
    "\n",
    "@jax.jit\n",
    "def ppo_loss_fn(params, apply_fn, obs, actions, log_probs_old, advantages, returns, clip_eps):\n",
    "    logits, values  = apply_fn({'params': params}, obs)\n",
    "    dist            = distrax.Categorical(logits=logits)\n",
    "    log_probs       = dist.log_prob(actions)\n",
    "\n",
    "    ratio           = jnp.exp(log_probs - log_probs_old)\n",
    "    clipped_ratio   = jnp.clip(ratio, 1.0 - clip_eps, 1.0 + clip_eps)\n",
    "    policy_loss     = -jnp.mean(jnp.minimum(ratio * advantages, clipped_ratio * advantages))\n",
    "\n",
    "    value_loss      = jnp.mean((returns - values)**2)\n",
    "    entropy_bonus   = jnp.mean(dist.entropy())\n",
    "\n",
    "    loss            = policy_loss + 0.5 * value_loss - 0.01 * entropy_bonus\n",
    "    return loss\n",
    "\n",
    "##################################\n",
    "#! Update Step for PPO\n",
    "##################################\n",
    "\n",
    "@jax.jit\n",
    "def update_step(state: PPOTrainState, batch, clip_eps: float):\n",
    "    grads = jax.grad(ppo_loss_fn)(  state.params, state.apply_fn,\n",
    "                                    batch['obs'], \n",
    "                                    batch['actions'],\n",
    "                                    batch['log_probs'], \n",
    "                                    batch['advantages'],\n",
    "                                    batch['returns'], \n",
    "                                    clip_eps)\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "##################################\n",
    "\n",
    "def create_train_state(rng      : jax.random.PRNGKey,\n",
    "                    obs_dim     : int,\n",
    "                    action_dim  : int,\n",
    "                    lr          : float = 3e-4,\n",
    "                    opt         : optax.GradientTransformation = optax.adam(3e-4)):\n",
    "    model   = ActorCritic(action_dim=action_dim)\n",
    "    params  = model.init(rng, jnp.ones((1, obs_dim)))['params']\n",
    "    tx      = optax.chain(optax.clip_by_global_norm(0.5), opt)\n",
    "    # Create the initial train state\n",
    "    return PPOTrainState.create(apply_fn=model.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c4dbbdaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PPOTrainState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m jnp.stack(obs), jnp.array(rewards), jnp.array(dones)\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m###################################\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m#! Function to run a rollout in the vectorized quantum environment\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m###################################\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_rollout\u001b[39m(envs        : VectorizedQuantumEnv,\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m                 state       : \u001b[43mPPOTrainState\u001b[49m, \n\u001b[32m     58\u001b[39m                 rng         : jax.random.PRNGKey,\n\u001b[32m     59\u001b[39m                 rollout_len : \u001b[38;5;28mint\u001b[39m):\n\u001b[32m     61\u001b[39m     num_envs    = envs.num_envs\n\u001b[32m     62\u001b[39m     obs         = envs.reset()\n",
      "\u001b[31mNameError\u001b[39m: name 'PPOTrainState' is not defined"
     ]
    }
   ],
   "source": [
    "class VectorizedQuantumEnv:\n",
    "    '''\n",
    "    Wrapper for vectorized quantum environments.\n",
    "    This class allows for parallel execution of multiple instances of the QuantumVectorEnv environment.\n",
    "    It initializes a specified number of environments and provides methods to reset and step through them in parallel.\n",
    "    \n",
    "    Parameters:\n",
    "        num_envs (int):\n",
    "            Number of parallel environments to create.\n",
    "        env_fn (Callable):\n",
    "            Function that creates an instance of the QuantumVectorEnv environment.\n",
    "    Raises:\n",
    "        ValueError: If num_envs is less than 1 or env_fn is not callable.\n",
    "    Usage:\n",
    "        envs = VectorizedQuantumEnv(num_envs=8, env_fn=lambda: QuantumVectorEnv(gamma=4, angles=[0.1, 0.2, 0.3]))\n",
    "        obs = envs.reset()\n",
    "        actions = jnp.array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, num_envs: int, env_fn: Callable):\n",
    "        '''\n",
    "        Initializes the VectorizedQuantumEnv with a specified number of environments.\n",
    "        Parameters:\n",
    "            num_envs (int):\n",
    "                Number of parallel environments to create.\n",
    "            env_fn (Callable):\n",
    "                Function that creates an instance of the QuantumVectorEnv environment.\n",
    "        Raises:\n",
    "            ValueError: If num_envs is less than 1 or env_fn is not callable.\n",
    "        '''\n",
    "        self.envs       = [env_fn() for _ in range(num_envs)]\n",
    "        self.num_envs   = num_envs\n",
    "\n",
    "    def reset(self):\n",
    "        obs = []\n",
    "        for env in self.envs:\n",
    "            o, _ = env.reset()\n",
    "            obs.append(o)\n",
    "        return jnp.stack(obs)\n",
    "\n",
    "    def step(self, actions):\n",
    "        obs, rewards, dones = [], [], []\n",
    "        for env, a in zip(self.envs, actions):\n",
    "            o, r, d, _, _ = env.step(int(a))\n",
    "            if d:\n",
    "                o, _ = env.reset()\n",
    "            obs.append(o)\n",
    "            rewards.append(r)\n",
    "            dones.append(d)\n",
    "        return jnp.stack(obs), jnp.array(rewards), jnp.array(dones)\n",
    "\n",
    "###################################\n",
    "#! Function to run a rollout in the vectorized quantum environment\n",
    "###################################\n",
    "\n",
    "def run_rollout(envs        : VectorizedQuantumEnv,\n",
    "                state       : PPOTrainState, \n",
    "                rng         : jax.random.PRNGKey,\n",
    "                rollout_len : int):\n",
    "    \n",
    "    num_envs    = envs.num_envs\n",
    "    obs         = envs.reset()\n",
    "    obs_list, actions, log_probs, rewards, dones, values = [], [], [], [], [], []\n",
    "\n",
    "    # Go through the rollout length to collect data\n",
    "    for _ in range(rollout_len):\n",
    "        rng, key                = jax.random.split(rng)\n",
    "        action, log_prob, value = select_action(state.params, state.apply_fn, obs, key)\n",
    "        next_obs, reward, done  = envs.step(action)\n",
    "\n",
    "        # Store the collected data\n",
    "        obs_list.append(obs)\n",
    "        actions.append(action)\n",
    "        log_probs.append(log_prob)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        values.append(value)\n",
    "        obs = next_obs\n",
    "\n",
    "    #! After the loop, we need to compute the last value for the last observation\n",
    "    last_value = select_action(state.params, state.apply_fn, obs, key)[2]\n",
    "    values.append(last_value)\n",
    "\n",
    "    #! reshape to (rollout_len * num_envs)\n",
    "    def stack_flat(xlist):\n",
    "        return jnp.reshape(jnp.stack(xlist), (-1,) + xlist[0].shape[1:])\n",
    "\n",
    "    flat_rewards        = jnp.reshape(jnp.stack(rewards), (rollout_len, num_envs))\n",
    "    flat_values         = jnp.stack(values)\n",
    "    flat_dones          = jnp.reshape(jnp.stack(dones), (rollout_len, num_envs))\n",
    "    advantages, returns = compute_gae(flat_rewards.T, flat_values.T, flat_dones.T)\n",
    "\n",
    "    return {\n",
    "        'obs'           : stack_flat(obs_list),\n",
    "        'actions'       : stack_flat(actions),\n",
    "        'log_probs'     : stack_flat(log_probs),\n",
    "        'advantages'    : jnp.reshape(advantages.T, (-1,)),\n",
    "        'returns'       : jnp.reshape(returns.T, (-1,))\n",
    "    }, rng\n",
    "\n",
    "def train_ppo(env_fn        : Callable, \n",
    "            total_steps     : int, \n",
    "            rollout_len     : int, \n",
    "            num_envs        : int = 8, \n",
    "            epochs          : int = 4,\n",
    "            minibatch_size  : int = 64):\n",
    "    envs        = VectorizedQuantumEnv(num_envs=num_envs, env_fn=env_fn)\n",
    "    obs_dim     = envs.reset().shape[-1]\n",
    "    action_dim  = envs.envs[0].action_space.n\n",
    "    rng         = jax.random.PRNGKey(0)\n",
    "    state       = create_train_state(rng, obs_dim, action_dim)\n",
    "\n",
    "    steps_per_rollout = rollout_len * num_envs\n",
    "\n",
    "    for step in range(0, total_steps, steps_per_rollout):\n",
    "        # Run a rollout to collect data\n",
    "        batch, rng = run_rollout(envs, state, rng, rollout_len)\n",
    "        \n",
    "        # Go through the epochs to update the model\n",
    "        for _ in range(epochs):\n",
    "            idxs = np.arange(steps_per_rollout)\n",
    "            np.random.shuffle(idxs)\n",
    "            \n",
    "            for start in range(0, steps_per_rollout, minibatch_size):\n",
    "                end     = start + minibatch_size\n",
    "                mb_idx  = idxs[start:end]\n",
    "                mbatch  = {k: v[mb_idx] for k, v in batch.items()}\n",
    "                state   = update_step(state, mbatch, clip_eps=0.2)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25406f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
